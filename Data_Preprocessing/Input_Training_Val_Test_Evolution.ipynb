{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This file is used to obtain the training, val & test data (only relevant to models which has been run on FullSWOF-2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'train'  ######## change this to test & val ########\n",
    "data_path = '/Users/ragini/Desktop/Thesis/FullSWOF_2D-1.09.01_win_2/Examples/Model_6_extended_flow/'\n",
    "params_path = glob.glob(os.path.join(data_path, split, '*.txt'))[0]     ######## check for param file in the folder ######## location\n",
    "examples_path = glob.glob(os.path.join(data_path, split, '*'))\n",
    "examples_path = [path for path in examples_path if path!=params_path]\n",
    "evol_paths = [os.path.join(i, 'Outputs/huz_evolution.dat')\n",
    "             for i in examples_path]\n",
    "              \n",
    "with open(params_path, 'r') as f:\n",
    "    params = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_evolution_file_to_datafram(evol_path, params, identifier):\n",
    "    dir_name = evol_path.split('/')[-3]\n",
    "    exp_parameters = params[dir_name]\n",
    "    slope = exp_parameters['slope']\n",
    "    friction_coeff = exp_parameters['friction_coeff']\n",
    "    \n",
    "    output =[]\n",
    "    fp = open(evol_path)\n",
    "    \n",
    "    for idx,line in enumerate(fp):\n",
    "        # Skipping first 5 lines\n",
    "        if idx<5:\n",
    "            continue\n",
    "        # Skipping new lines\n",
    "        if line =='\\n':\n",
    "            continue\n",
    "        # From # time extracting time\n",
    "        elif line[:6] == '# time':\n",
    "            extract_time = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", line)\n",
    "            \n",
    "        # Extracting all the input variables and appending time as first element\n",
    "        else:\n",
    "            extract_input = extract_time + re.split(r'\\t\\s*', line.rstrip('\\n'))\n",
    "            output.append(extract_input)\n",
    "\n",
    "    fp.close()\n",
    "    \n",
    "    # From extracted input creating dataframe\n",
    "    evol_df = pd.DataFrame(output, columns=['time','i','(j-0.5)*dy','h','u','v[i][j]',\n",
    "                              'h[i][j]+z[i][j]','z[i][j]','norm_U[i][j]','Fr[i][j] (Froude)','qx[i][j]',\n",
    "                              'qy[i][j]','q'])\n",
    "    # Dropping columns which are not required, FROUDE NUMBER CAN BE KEPT FOR DEBUGGING\n",
    "    evol_df = evol_df.drop(columns=['(j-0.5)*dy','v[i][j]',\n",
    "                              'h[i][j]+z[i][j]','z[i][j]','norm_U[i][j]','qx[i][j]','Fr[i][j] (Froude)',\n",
    "                              'qy[i][j]'])\n",
    "    # Keeping only points that are of interest\n",
    "#     evol_df = evol_df[evol_df['i'].isin(['101','201','301','401'])].reset_index(drop=True)\n",
    "\n",
    "    # Grouping everythong base on time and concatenating as strings\n",
    "#     evol_df  = evol_df.groupby(['time']).agg({'i':','.join, 'u':','.join, 'h':','.join, 'q':','.join}).reset_index()\n",
    "    \n",
    "    # Converting time to float and sorting based on time\n",
    "    evol_df['time'] = evol_df['time'].astype(float)\n",
    "    evol_df['x'] = evol_df['i'].astype(int)\n",
    "    evol_df = evol_df.drop(columns=['i'])\n",
    "    evol_df['h'] = evol_df['h'].astype(float)\n",
    "    evol_df['u'] = evol_df['u'].astype(float)\n",
    "    evol_df['q'] = evol_df['q'].astype(float)\n",
    "\n",
    "    evol_df = evol_df.sort_values('time')\n",
    "    evol_df['slope'] = slope\n",
    "    evol_df['friction_coeff'] = friction_coeff\n",
    "    evol_df['identifier'] = identifier # To identify different hydrogrpahs later\n",
    "    # Calculating du_dt\n",
    "#     all_du_dt = [None] # Initial value None as it has previous value\n",
    "#     for idx in range(1,len(evol_df)):\n",
    "#         u_before = list(map(float,evol_df['u'][idx-1].split(',')))\n",
    "#         u_now = list(map(float,evol_df['u'][idx].split(',')))\n",
    "#         du = [u_now[i] - u_before[i] for i in range(len(u_before))]\n",
    "#         dt = evol_df['time'][idx] - evol_df['time'][idx-1]\n",
    "#         du_dt = du/dt\n",
    "#         all_du_dt.append(','.join(map(str, du_dt)))\n",
    "    \n",
    "    # Storing du_dt and removing u\n",
    "#     evol_df['du_dt'] = all_du_dt\n",
    "#     evol_df = evol_df.drop(columns=['u'])\n",
    "    \n",
    "    # Dropping first row as it doesn't have du_dt\n",
    "#     evol_df = evol_df.drop(0).reset_index(drop=True)\n",
    "    return evol_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_evol_hydrographs = pd.DataFrame()\n",
    "# for evol_path,hydrograph in zip(evol_paths,hydrographs):\n",
    "for identifier,evol_path in enumerate(evol_paths):\n",
    "\n",
    "    # Parsing a hydrograph\n",
    "    evol = parse_evolution_file_to_datafram(evol_path, params, 8 +identifier)\n",
    "    # Adding hydrograph column to differentiate different hydrographs\n",
    "#     evol['hydrograph'] = hydrograph\n",
    "    \n",
    "    # COncatenating dataframes\n",
    "    frames = [all_evol_hydrographs, evol] \n",
    "    all_evol_hydrographs = pd.concat(frames)\n",
    "    \n",
    "all_evol_hydrographs = all_evol_hydrographs.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving File as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_evol_hydrographs.to_csv(data_path + split +'.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
