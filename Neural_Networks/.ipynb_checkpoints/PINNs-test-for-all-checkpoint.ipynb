{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Physics Informed Neural Network (PINN) test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:54:43.700689Z",
     "iopub.status.busy": "2020-09-03T18:54:43.699893Z",
     "iopub.status.idle": "2020-09-03T18:54:51.337199Z",
     "shell.execute_reply": "2020-09-03T18:54:51.336347Z"
    },
    "papermill": {
     "duration": 7.66074,
     "end_time": "2020-09-03T18:54:51.337335",
     "exception": false,
     "start_time": "2020-09-03T18:54:43.676595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "# from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# %load_ext tensorboard\n",
    "# import tensorboard\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:54:51.362612Z",
     "iopub.status.busy": "2020-09-03T18:54:51.361681Z",
     "iopub.status.idle": "2020-09-03T18:54:51.364781Z",
     "shell.execute_reply": "2020-09-03T18:54:51.364047Z"
    },
    "papermill": {
     "duration": 0.017802,
     "end_time": "2020-09-03T18:54:51.364901",
     "exception": false,
     "start_time": "2020-09-03T18:54:51.347099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008631,
     "end_time": "2020-09-03T18:54:51.384383",
     "exception": false,
     "start_time": "2020-09-03T18:54:51.375752",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR_PATH = '/Users/ge72vep/Desktop/thesis/'\n",
    "DATA_PATH = 'Data/Model_8/'\n",
    "MODEL_PATH = 'models/model_8_w_1sec_batch2.h5'######## Check the data path ######## \n",
    "IMAGES_PATH = 'results/images/'\n",
    "VIDEOS_PATH = 'results/videos/'\n",
    "EXP_NAME = 'physics_exp_1sec_M8_w_batch2' ######## Check file name ######## \n",
    "VIDEO_NAME = 'phy_1sec_M8_w_2_batch3'  ######## Check file name ######## \n",
    "metrics_dir = 'results/test_metrics/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = os.path.join(BASE_DIR_PATH, DATA_PATH)\n",
    "save_model_path = os.path.join(BASE_DIR_PATH, MODEL_PATH)\n",
    "save_images_path = os.path.join(BASE_DIR_PATH, IMAGES_PATH, EXP_NAME)\n",
    "save_video_path = os.path.join(BASE_DIR_PATH, VIDEOS_PATH, VIDEO_NAME)\n",
    "save_results_path = os.path.join(BASE_DIR_PATH, 'models', EXP_NAME+'.csv')\n",
    "save_test_results_path = os.path.join(BASE_DIR_PATH, metrics_dir, 'test_'+ EXP_NAME+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.00855,
     "end_time": "2020-09-03T18:54:51.428366",
     "exception": false,
     "start_time": "2020-09-03T18:54:51.419816",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "#### Loading dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:54:51.456883Z",
     "iopub.status.busy": "2020-09-03T18:54:51.456152Z",
     "iopub.status.idle": "2020-09-03T18:55:20.110167Z",
     "shell.execute_reply": "2020-09-03T18:55:20.109464Z"
    },
    "papermill": {
     "duration": 28.673092,
     "end_time": "2020-09-03T18:55:20.110292",
     "exception": false,
     "start_time": "2020-09-03T18:54:51.437200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(os.path.join(PATH_TO_DATA, 'test.csv')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.sort_values(['identifier','x','time']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncomment the next cell if testing for 3 or 5 seconds and adjust `t` accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = 5\n",
    "#test_df = test_df.iloc[::5].reset_index(drop=True) #5sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:55:20.590412Z",
     "iopub.status.busy": "2020-09-03T18:55:20.589341Z",
     "iopub.status.idle": "2020-09-03T18:56:42.362580Z",
     "shell.execute_reply": "2020-09-03T18:56:42.361758Z"
    },
    "papermill": {
     "duration": 82.242915,
     "end_time": "2020-09-03T18:56:42.362715",
     "exception": false,
     "start_time": "2020-09-03T18:55:20.119800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test = np.array(test_df[['x','time', 'q', 'friction_coeff', 'slope']].values.tolist()) #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:57:21.606283Z",
     "iopub.status.busy": "2020-09-03T18:56:59.759759Z",
     "iopub.status.idle": "2020-09-03T18:57:37.604965Z",
     "shell.execute_reply": "2020-09-03T18:57:37.604326Z"
    },
    "papermill": {
     "duration": 55.232753,
     "end_time": "2020-09-03T18:57:37.605097",
     "exception": false,
     "start_time": "2020-09-03T18:56:42.372344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y_test = np.array(test_df[['u','h']].values.tolist())   #test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008895,
     "end_time": "2020-09-03T18:57:37.623182",
     "exception": false,
     "start_time": "2020-09-03T18:57:37.614287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:57:37.646495Z",
     "iopub.status.busy": "2020-09-03T18:57:37.645744Z",
     "iopub.status.idle": "2020-09-03T18:57:37.649313Z",
     "shell.execute_reply": "2020-09-03T18:57:37.648580Z"
    },
    "papermill": {
     "duration": 0.017209,
     "end_time": "2020-09-03T18:57:37.649445",
     "exception": false,
     "start_time": "2020-09-03T18:57:37.632236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs= 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008778,
     "end_time": "2020-09-03T18:57:37.667128",
     "exception": false,
     "start_time": "2020-09-03T18:57:37.658350",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Model  with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:57:37.690242Z",
     "iopub.status.busy": "2020-09-03T18:57:37.689541Z",
     "iopub.status.idle": "2020-09-03T18:57:37.692914Z",
     "shell.execute_reply": "2020-09-03T18:57:37.692342Z"
    },
    "papermill": {
     "duration": 0.017064,
     "end_time": "2020-09-03T18:57:37.693031",
     "exception": false,
     "start_time": "2020-09-03T18:57:37.675967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_val_loss = np.inf\n",
    "best_model = -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:57:37.723239Z",
     "iopub.status.busy": "2020-09-03T18:57:37.722249Z",
     "iopub.status.idle": "2020-09-03T18:57:37.725716Z",
     "shell.execute_reply": "2020-09-03T18:57:37.724996Z"
    },
    "papermill": {
     "duration": 0.023284,
     "end_time": "2020-09-03T18:57:37.725823",
     "exception": false,
     "start_time": "2020-09-03T18:57:37.702539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['n1','n2','n3', 'epochs', 'reg',\n",
    "                               'val_r2', 'val_nse', 'val_mse', 'val_mae', 'val_mape'])\n",
    "layer_1_neurons = np.arange(15,16,10)\n",
    "layer_2_neurons = np.arange(5,26,10)\n",
    "layer_3_neurons = np.arange(5,26,10)\n",
    "reg_consts = [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:57:37.752901Z",
     "iopub.status.busy": "2020-09-03T18:57:37.752081Z",
     "iopub.status.idle": "2020-09-03T18:57:37.755228Z",
     "shell.execute_reply": "2020-09-03T18:57:37.754686Z"
    },
    "papermill": {
     "duration": 0.020527,
     "end_time": "2020-09-03T18:57:37.755338",
     "exception": false,
     "start_time": "2020-09-03T18:57:37.734811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def r_square(y_true, y_pred):\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    mx = K.mean(x, axis=0)\n",
    "    my = K.mean(y, axis=0)\n",
    "    xm, ym = x - mx, y - my\n",
    "    r_num = K.square(K.sum(xm * ym))\n",
    "    x_square_sum = K.sum(xm * xm)\n",
    "    y_square_sum = K.sum(ym * ym)\n",
    "    r_den = (x_square_sum * y_square_sum) + K.epsilon()\n",
    "    \n",
    "    r = r_num / r_den\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:57:37.781819Z",
     "iopub.status.busy": "2020-09-03T18:57:37.780806Z",
     "iopub.status.idle": "2020-09-03T18:57:37.783340Z",
     "shell.execute_reply": "2020-09-03T18:57:37.783923Z"
    },
    "papermill": {
     "duration": 0.019312,
     "end_time": "2020-09-03T18:57:37.784065",
     "exception": false,
     "start_time": "2020-09-03T18:57:37.764753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def NSE(y_true, y_pred):\n",
    "\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    y_true = K.flatten(y_true)\n",
    "\n",
    "    \n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:57:37.814038Z",
     "iopub.status.busy": "2020-09-03T18:57:37.813231Z",
     "iopub.status.idle": "2020-09-03T18:57:37.816289Z",
     "shell.execute_reply": "2020-09-03T18:57:37.815740Z"
    },
    "papermill": {
     "duration": 0.023217,
     "end_time": "2020-09-03T18:57:37.816410",
     "exception": false,
     "start_time": "2020-09-03T18:57:37.793193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#PDE Loss Function\n",
    "def custom_loss(grads_inputs):\n",
    "    du_dx, du_dt, dh_dx, fric_coeff, slope = grads_inputs[:,0], grads_inputs[:,1], grads_inputs[:,2], grads_inputs[:,3], grads_inputs[:,4]\n",
    "    g = K.constant(9.8)\n",
    "    # Create a loss function that adds the MSE loss to the mean of all squared activations of a specific layer\n",
    "    def loss(y_true,y_pred):\n",
    "        loss_saint_venant = du_dt + y_pred[:,0] * du_dx + g*dh_dx + g*slope + g*K.square(fric_coeff) * K.square(y_true[:,0])/(K.pow(y_true[:,1], 4/3) + K.epsilon())\n",
    "        l = K.mean(K.square(loss_saint_venant))\n",
    "\n",
    "        return l+ K.sum(K.mean(K.square(y_pred - y_true), axis=0))\n",
    "   \n",
    "    # Return a function\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization (Images & Videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_grads_inputs = K.placeholder(shape=(None,5))\n",
    "\n",
    "best_model = tf.keras.models.load_model(save_model_path, custom_objects={'loss':custom_loss(calc_grads_inputs),\n",
    "                                                                         'NSE':NSE,'r_square':r_square})\n",
    "points = 500\n",
    "time = 3600\n",
    "separator = '\\\\' # \\\\ for windows / for mac \n",
    "for identifier in range(len(test_df['identifier'].unique())): #in range(1):\n",
    "\n",
    "    tmp_df = test_df[test_df['identifier']==identifier].sort_values(['time','x']).reset_index(drop=True)\n",
    "    X_ident = np.array(tmp_df[['x','time', 'q', 'friction_coeff', 'slope']].values.tolist())\n",
    "    Y_ident = np.array(tmp_df[['u','h']].values.tolist())\n",
    "    predictions_ident = best_model.predict(X_ident)\n",
    "    tmp_df['pred_u'] = predictions_ident[:,0]\n",
    "    tmp_df['pred_h'] = predictions_ident[:,1]\n",
    "\n",
    "    save_images_identifier_path = os.path.join(save_images_path , 'identifier_'+str(identifier))\n",
    "    save_videos_h_identifier_path_points = os.path.join(save_video_path,  'h_points_identifier_'+str(identifier) +'.mp4')\n",
    "    save_videos_h_identifier_path_time = os.path.join(save_video_path ,  'h_time_identifier_'+str(identifier) +'.mp4')\n",
    "    save_videos_u_identifier_path_points = os.path.join(save_video_path ,  'u_points_identifier_'+str(identifier) +'.mp4')\n",
    "    save_videos_u_identifier_path_time = os.path.join(save_video_path,  'u_time_identifier_'+str(identifier) +'.mp4')\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(save_video_path):\n",
    "        os.makedirs(save_video_path)\n",
    "        \n",
    "    if not os.path.exists(save_images_identifier_path):\n",
    "        os.makedirs(save_images_identifier_path)\n",
    "        os.makedirs(os.path.join(save_images_identifier_path  , 'h_points'))\n",
    "        os.makedirs(os.path.join(save_images_identifier_path , 'h_time'))\n",
    "        os.makedirs(os.path.join(save_images_identifier_path , 'u_time'))\n",
    "        os.makedirs(os.path.join(save_images_identifier_path , 'u_points'))\n",
    "\n",
    "\n",
    "    #height images\n",
    "    max_y_axis = max(tmp_df['h'].max(), tmp_df['pred_h'].max()) + 2\n",
    "\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    for index in range(points):\n",
    "        point = 2*index + 1\n",
    "        plt.clf()\n",
    "        plt.cla()\n",
    "        #ax = plt.axes()\n",
    "        x_df = tmp_df[tmp_df['x']==point]        \n",
    "        plt.plot(x_df['time'], x_df['pred_h'], label ='prediction')\n",
    "        plt.plot(x_df['time'], x_df['h'], label ='actual')\n",
    "        plt.legend()\n",
    "        # plt.xticks(range(len(predictions[:,0])), rotation = 45)\n",
    "        plt.xlabel('Time')\n",
    "        plt.title('Observed and Predicted height at x='+str(point))\n",
    "        plt.axis([0, x_df['time'].max() + 10 , 0, max_y_axis])\n",
    "        plt.savefig(os.path.join(save_images_identifier_path , 'h_time', str(point)+'.png') , dpi=200)\n",
    "        #plt.show()\n",
    "\n",
    "\n",
    "    import glob\n",
    "    import cv2\n",
    "    img_fns = glob.glob(os.path.join(save_images_identifier_path , 'h_time', '*.png'))\n",
    "    img_nums = [int(fn.split(separator)[-1].split('.')[0]) for fn in img_fns]\n",
    "    sorted_fns = np.array(img_fns)[np.argsort(img_nums)]\n",
    "\n",
    "    img_array = []\n",
    "    for filename in sorted_fns:\n",
    "        img = cv2.imread(filename)\n",
    "        height, width, layers = img.shape\n",
    "        size = (width,height)\n",
    "        img_array.append(img)\n",
    "        #video.write(img)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    out = cv2.VideoWriter(save_videos_h_identifier_path_time ,cv2.VideoWriter_fourcc(*'FMP4'), 15, size)\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(img_array)):\n",
    "        out.write(img_array[i])\n",
    "    out.release()\n",
    "\n",
    "\n",
    "    #velocity images\n",
    "    max_y_axis = max(tmp_df['u'].max(), tmp_df['pred_u'].max()) + 1\n",
    "\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    for index in range(points):\n",
    "        point = 2*index + 1\n",
    "        plt.clf()\n",
    "        plt.cla()\n",
    "        #ax = plt.axes()\n",
    "        x_df = tmp_df[tmp_df['x']==point]        \n",
    "        plt.plot(x_df['time'], x_df['pred_u'], label ='prediction')\n",
    "        plt.plot(x_df['time'], x_df['u'], label ='actual')\n",
    "        plt.legend()\n",
    "        # plt.xticks(range(len(predictions[:,0])), rotation = 45)\n",
    "        plt.xlabel('Time')\n",
    "        plt.title('Observed and Predicted velocity at x='+str(point))\n",
    "        plt.axis([0, x_df['time'].max() + 10, 0, max_y_axis])\n",
    "        plt.savefig(os.path.join(save_images_identifier_path, 'u_time', str(point)+'.png') , dpi=200)\n",
    "        #plt.show()\n",
    "\n",
    "\n",
    "    import glob\n",
    "    import cv2\n",
    "    img_fns = glob.glob(os.path.join(save_images_identifier_path , 'u_time', '*.png'))\n",
    "    img_nums = [int(fn.split(separator)[-1].split('.')[0]) for fn in img_fns]\n",
    "    sorted_fns = np.array(img_fns)[np.argsort(img_nums)]\n",
    "\n",
    "    img_array = []\n",
    "    for filename in sorted_fns:\n",
    "        img = cv2.imread(filename)\n",
    "        height, width, layers = img.shape\n",
    "        size = (width,height)\n",
    "        img_array.append(img)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    out = cv2.VideoWriter(save_videos_u_identifier_path_time ,cv2.VideoWriter_fourcc(*'FMP4'), 15, size)\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(img_array)):\n",
    "        out.write(img_array[i])\n",
    "    out.release()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_grads_inputs = K.placeholder(shape=(None,5))\n",
    "\n",
    "best_model = tf.keras.models.load_model(save_model_path, custom_objects={'loss':custom_loss(calc_grads_inputs),\n",
    "                                                                        'NSE':NSE,'r_square':r_square})\n",
    "test_results = pd.DataFrame(columns=['identifier', 'exp_name',  'q_max', 'slope', 'friction_coeff','u_nse','u_mse','u_r2', 'h_nse', 'h_mse',\n",
    "                               'h_r2', 'avg_nse', 'avg_r2', 'avg_mse'])\n",
    "\n",
    "if not os.path.exists(os.path.join(BASE_DIR_PATH, metrics_dir)):\n",
    "    os.makedirs(os.path.join(BASE_DIR_PATH, metrics_dir))\n",
    "for identifier in range(len(test_df['identifier'].unique())):\n",
    "    tmp_df = test_df[test_df['identifier']==identifier].sort_values(['time','x']).reset_index(drop=True)\n",
    "    X_ident = np.array(tmp_df[['x','time', 'q', 'friction_coeff', 'slope']].values.tolist())\n",
    "    Y_ident = tf.convert_to_tensor(np.array(tmp_df[['u','h']].values.tolist()).astype(np.float32))\n",
    "    predictions_ident = tf.convert_to_tensor(best_model.predict(X_ident))\n",
    "    \n",
    "    s = tmp_df['slope'].unique()[0]\n",
    "    q_max = tmp_df['q'].max()\n",
    "    f_coeff = tmp_df['friction_coeff'].unique()[0]\n",
    "\n",
    "    u_nse = K.eval(NSE(Y_ident[:,0], predictions_ident[:,0]))\n",
    "    u_r2 = K.eval(r_square(Y_ident[:,0], predictions_ident[:,0]))\n",
    "    u_mse = K.get_value(tf.keras.metrics.mse(Y_ident[:,0], predictions_ident[:,0]))\n",
    "\n",
    "    h_nse = K.eval(NSE(Y_ident[:,1], predictions_ident[:,1]))\n",
    "    h_r2 = K.eval(r_square(Y_ident[:,1], predictions_ident[:,1]))\n",
    "    h_mse = K.get_value(tf.keras.metrics.mse(Y_ident[:,1], predictions_ident[:,1]))\n",
    "\n",
    "    avg_nse = (u_nse + h_nse)/2.0\n",
    "    avg_r2 = (u_r2 + h_r2)/2.0\n",
    "    avg_mse = (u_mse + h_mse)/2.0\n",
    "    \n",
    "    test_results = test_results.append({'identifier':identifier, 'exp_name':EXP_NAME, 'q_max' : q_max, 'slope' : s, 'friction_coeff':f_coeff,\n",
    "                                        'u_nse' : u_nse,'u_mse': u_mse,'u_r2':u_r2, 'h_nse':h_nse, 'h_mse':h_mse,\n",
    "                               'h_r2':h_r2, 'avg_nse':avg_nse, 'avg_r2':avg_r2, 'avg_mse':avg_mse}, ignore_index=True)\n",
    "\n",
    "test_results.to_csv(save_test_results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_grads_inputs = K.placeholder(shape=(None,5))\n",
    "\n",
    "best_model = tf.keras.models.load_model(save_model_path, custom_objects={'loss':custom_loss(calc_grads_inputs),\n",
    "                                                                        'NSE':NSE,'r_square':r_square})\n",
    "identifier = 0\n",
    "tmp_df = test_df[test_df['identifier']==identifier].sort_values(['time','x']).reset_index(drop=True)\n",
    "X_ident = np.array(tmp_df[['x','time', 'q', 'friction_coeff', 'slope']].values.tolist())\n",
    "Y_ident = np.array(tmp_df[['u','h']].values.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "predictions_ident = best_model.predict(X_ident, batch_size = len(X_ident))\n",
    "total_time = time.time() - start\n",
    "avg_time = total_time/len(predictions_ident)\n",
    "print('Total time for {:d} iterations is {:.4f} seconds'.format(len(predictions_ident), total_time))\n",
    "print('Average time for inference is {:.16f} seconds'.format(avg_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "predictions_ident = best_model.predict(X_ident, batch_size = 32)\n",
    "total_time = time.time() - start\n",
    "avg_time = total_time/len(predictions_ident)\n",
    "print('Total time for {:d} iterations is {:.4f} seconds'.format(len(predictions_ident), total_time))\n",
    "print('Average time for inference is {:.16f} seconds'.format(avg_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "predictions_ident = best_model.predict(X_ident, batch_size = 128)\n",
    "total_time = time.time() - start\n",
    "avg_time = total_time/len(predictions_ident)\n",
    "print('Total time for {:d} iterations is {:.4f} seconds'.format(len(predictions_ident), total_time))\n",
    "print('Average time for inference is {:.16f} seconds'.format(avg_time))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 1095.738968,
   "end_time": "2020-09-03T19:12:53.052539",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-03T18:54:37.313571",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
