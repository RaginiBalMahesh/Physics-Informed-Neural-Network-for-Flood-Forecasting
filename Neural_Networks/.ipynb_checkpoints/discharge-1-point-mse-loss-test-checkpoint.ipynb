{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:54:43.700689Z",
     "iopub.status.busy": "2020-09-03T18:54:43.699893Z",
     "iopub.status.idle": "2020-09-03T18:54:51.337199Z",
     "shell.execute_reply": "2020-09-03T18:54:51.336347Z"
    },
    "papermill": {
     "duration": 7.66074,
     "end_time": "2020-09-03T18:54:51.337335",
     "exception": false,
     "start_time": "2020-09-03T18:54:43.676595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "# from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# %load_ext tensorboard\n",
    "# import tensorboard\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:54:51.362612Z",
     "iopub.status.busy": "2020-09-03T18:54:51.361681Z",
     "iopub.status.idle": "2020-09-03T18:54:51.364781Z",
     "shell.execute_reply": "2020-09-03T18:54:51.364047Z"
    },
    "papermill": {
     "duration": 0.017802,
     "end_time": "2020-09-03T18:54:51.364901",
     "exception": false,
     "start_time": "2020-09-03T18:54:51.347099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008631,
     "end_time": "2020-09-03T18:54:51.384383",
     "exception": false,
     "start_time": "2020-09-03T18:54:51.375752",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:54:51.408391Z",
     "iopub.status.busy": "2020-09-03T18:54:51.407364Z",
     "iopub.status.idle": "2020-09-03T18:54:51.410796Z",
     "shell.execute_reply": "2020-09-03T18:54:51.410077Z"
    },
    "papermill": {
     "duration": 0.017734,
     "end_time": "2020-09-03T18:54:51.410910",
     "exception": false,
     "start_time": "2020-09-03T18:54:51.393176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH_TO_DATA = '/Users/ge72vep/Desktop/thesis/Data/Model_6/'\n",
    "save_model_path = '/Users/ge72vep/Desktop/thesis/results/model6_mse_batch1.h5'\n",
    "save_results_path = '/Users/ge72vep/Desktop/thesis/results/results6_mse_batch1.csv'\n",
    "save_test_results_path = '/Users/ge72vep/Desktop/thesis/results/test_metrics/test_model6_mse_batch1.csv'\n",
    "metrics_dir = 'results/test_metrics/'\n",
    "BASE_DIR_PATH = '/Users/ge72vep/Desktop/thesis/'\n",
    "EXP_NAME = 'model6_mse_batch1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.00855,
     "end_time": "2020-09-03T18:54:51.428366",
     "exception": false,
     "start_time": "2020-09-03T18:54:51.419816",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "#### Loading dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:54:51.456883Z",
     "iopub.status.busy": "2020-09-03T18:54:51.456152Z",
     "iopub.status.idle": "2020-09-03T18:55:20.110167Z",
     "shell.execute_reply": "2020-09-03T18:55:20.109464Z"
    },
    "papermill": {
     "duration": 28.673092,
     "end_time": "2020-09-03T18:55:20.110292",
     "exception": false,
     "start_time": "2020-09-03T18:54:51.437200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(os.path.join(PATH_TO_DATA, 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:55:20.590412Z",
     "iopub.status.busy": "2020-09-03T18:55:20.589341Z",
     "iopub.status.idle": "2020-09-03T18:56:42.362580Z",
     "shell.execute_reply": "2020-09-03T18:56:42.361758Z"
    },
    "papermill": {
     "duration": 82.242915,
     "end_time": "2020-09-03T18:56:42.362715",
     "exception": false,
     "start_time": "2020-09-03T18:55:20.119800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test = np.array(test_df[['x','time', 'q', 'friction_coeff', 'slope']].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:57:21.606283Z",
     "iopub.status.busy": "2020-09-03T18:56:59.759759Z",
     "iopub.status.idle": "2020-09-03T18:57:37.604965Z",
     "shell.execute_reply": "2020-09-03T18:57:37.604326Z"
    },
    "papermill": {
     "duration": 55.232753,
     "end_time": "2020-09-03T18:57:37.605097",
     "exception": false,
     "start_time": "2020-09-03T18:56:42.372344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Y_train = np.array(train_df[['u','h']].values.tolist())\n",
    "# Y_val = np.array(val_df[['u','h']].values.tolist())\n",
    "Y_test = np.array(test_df[['u','h']].values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008895,
     "end_time": "2020-09-03T18:57:37.623182",
     "exception": false,
     "start_time": "2020-09-03T18:57:37.614287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:57:37.646495Z",
     "iopub.status.busy": "2020-09-03T18:57:37.645744Z",
     "iopub.status.idle": "2020-09-03T18:57:37.649313Z",
     "shell.execute_reply": "2020-09-03T18:57:37.648580Z"
    },
    "papermill": {
     "duration": 0.017209,
     "end_time": "2020-09-03T18:57:37.649445",
     "exception": false,
     "start_time": "2020-09-03T18:57:37.632236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs= 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008778,
     "end_time": "2020-09-03T18:57:37.667128",
     "exception": false,
     "start_time": "2020-09-03T18:57:37.658350",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Model  with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:57:37.690242Z",
     "iopub.status.busy": "2020-09-03T18:57:37.689541Z",
     "iopub.status.idle": "2020-09-03T18:57:37.692914Z",
     "shell.execute_reply": "2020-09-03T18:57:37.692342Z"
    },
    "papermill": {
     "duration": 0.017064,
     "end_time": "2020-09-03T18:57:37.693031",
     "exception": false,
     "start_time": "2020-09-03T18:57:37.675967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_val_loss = np.inf\n",
    "best_model = -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:57:37.723239Z",
     "iopub.status.busy": "2020-09-03T18:57:37.722249Z",
     "iopub.status.idle": "2020-09-03T18:57:37.725716Z",
     "shell.execute_reply": "2020-09-03T18:57:37.724996Z"
    },
    "papermill": {
     "duration": 0.023284,
     "end_time": "2020-09-03T18:57:37.725823",
     "exception": false,
     "start_time": "2020-09-03T18:57:37.702539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['n1','n2','n3', 'epochs', 'reg',\n",
    "                               'val_r2', 'val_nse', 'val_mse', 'val_mae', 'val_mape'])\n",
    "layer_1_neurons = np.arange(15,16,10)\n",
    "layer_2_neurons = np.arange(5,26,10)\n",
    "layer_3_neurons = np.arange(5,26,10)\n",
    "reg_consts = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:57:37.752901Z",
     "iopub.status.busy": "2020-09-03T18:57:37.752081Z",
     "iopub.status.idle": "2020-09-03T18:57:37.755228Z",
     "shell.execute_reply": "2020-09-03T18:57:37.754686Z"
    },
    "papermill": {
     "duration": 0.020527,
     "end_time": "2020-09-03T18:57:37.755338",
     "exception": false,
     "start_time": "2020-09-03T18:57:37.734811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def r_square(y_true, y_pred):\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    mx = K.mean(x, axis=0)\n",
    "    my = K.mean(y, axis=0)\n",
    "    xm, ym = x - mx, y - my\n",
    "    r_num = K.square(K.sum(xm * ym))\n",
    "    x_square_sum = K.sum(xm * xm)\n",
    "    y_square_sum = K.sum(ym * ym)\n",
    "    r_den = (x_square_sum * y_square_sum) + K.epsilon()\n",
    "    \n",
    "    r = r_num / r_den\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:57:37.781819Z",
     "iopub.status.busy": "2020-09-03T18:57:37.780806Z",
     "iopub.status.idle": "2020-09-03T18:57:37.783340Z",
     "shell.execute_reply": "2020-09-03T18:57:37.783923Z"
    },
    "papermill": {
     "duration": 0.019312,
     "end_time": "2020-09-03T18:57:37.784065",
     "exception": false,
     "start_time": "2020-09-03T18:57:37.764753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def NSE(y_true, y_pred):\n",
    "\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    y_true = K.flatten(y_true)\n",
    "\n",
    "    \n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:57:37.814038Z",
     "iopub.status.busy": "2020-09-03T18:57:37.813231Z",
     "iopub.status.idle": "2020-09-03T18:57:37.816289Z",
     "shell.execute_reply": "2020-09-03T18:57:37.815740Z"
    },
    "papermill": {
     "duration": 0.023217,
     "end_time": "2020-09-03T18:57:37.816410",
     "exception": false,
     "start_time": "2020-09-03T18:57:37.793193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_loss(grads_inputs):\n",
    "    du_dx, du_dt, dh_dx, fric_coeff, slope = grads_inputs[:,0], grads_inputs[:,1], grads_inputs[:,2], grads_inputs[:,3], grads_inputs[:,4]\n",
    "    g = K.constant(9.8)\n",
    "    # Create a loss function that adds the MSE loss to the mean of all squared activations of a specific layer\n",
    "    def loss(y_true,y_pred):\n",
    "        loss_saint_venant = du_dt + y_pred[:,0] * du_dx + g*dh_dx + g*slope + g*K.square(fric_coeff) * K.square(y_true[:,0])/(K.pow(y_true[:,1], 2) + K.epsilon())\n",
    "        l = K.mean(K.square(loss_saint_venant))\n",
    "#         print(y_pred-y_true)\n",
    "#         print(K.square(y_pred - y_true))\n",
    "#         print(K.sum(K.mean(K.square(y_pred - y_true), axis=0)))\n",
    "#         print(loss_saint_venant)\n",
    "#         print(K.sum(K.mean(K.square(loss_saint_venant), axis=0)))\n",
    "        return l+ K.sum(K.mean(K.square(y_pred - y_true), axis=0))\n",
    "   \n",
    "    # Return a function\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:57:37.859913Z",
     "iopub.status.busy": "2020-09-03T18:57:37.858948Z",
     "iopub.status.idle": "2020-09-03T19:08:09.137913Z",
     "shell.execute_reply": "2020-09-03T19:08:09.137246Z"
    },
    "papermill": {
     "duration": 631.312345,
     "end_time": "2020-09-03T19:08:09.138043",
     "exception": false,
     "start_time": "2020-09-03T18:57:37.825698",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 5 5 0\n",
      "WARNING:tensorflow:From D:\\Users\\ge72vep\\.conda\\envs\\thesis\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-3b5ca411d26a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[1;31m#fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0mearly_stopping_monitor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping_monitor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;31m# Saving results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "for reg in reg_consts:\n",
    "    for n1 in layer_1_neurons:\n",
    "        for n2 in layer_2_neurons:\n",
    "            for n3 in layer_3_neurons:\n",
    "                print(n1,n2,n3,reg)\n",
    "                K.clear_session()\n",
    "                model = Sequential()\n",
    "                #model.add(Dense(n1, activation = 'relu', input_shape = (1,)))\n",
    "                model.add(Dense(n1, activation = 'relu', kernel_regularizer=l2(reg),input_shape = (5,)))\n",
    "                model.add(Dense(n2, activation = 'relu', kernel_regularizer=l2(reg)))\n",
    "                model.add(Dense(n3, activation = 'relu', kernel_regularizer=l2(reg)))\n",
    "\n",
    "                model.add(Dense(2))\n",
    "                #grads_u = K.gradients(model.output[:,0], model.input)[0]\n",
    "                #grads_h = K.gradients(model.output[:,1], model.input)[0]\n",
    "\n",
    "\n",
    "                #du_dx, du_dt, dh_dx = grads_u[:,0],grads_u[:,1],grads_h[:,0]\n",
    "                #calc_grads_inputs = K.stack((du_dx, du_dt, dh_dx, model.input[:,3],model.input[:,4]), axis=1)\n",
    "                # model.summary()\n",
    "                #Compile the model\n",
    "                model.compile(optimizer = 'adam', loss = ['mse'], metrics=['mape', 'mae', 'mse',NSE, r_square])\n",
    "                #fit the model\n",
    "                early_stopping_monitor = EarlyStopping(patience = 1, verbose=False)\n",
    "                history = model.fit(X_train,Y_train, epochs=epochs, batch_size=128, validation_data=(X_val,Y_val), callbacks=[early_stopping_monitor])\n",
    "\n",
    "                # Saving results\n",
    "                val_loss = history.history['val_loss'][-1]\n",
    "                val_mae = history.history['val_mae'][-1]\n",
    "                val_mse = history.history['val_mse'][-1]\n",
    "                val_mape = history.history['val_mape'][-1]\n",
    "                val_nse = history.history['val_NSE'][-1]\n",
    "                val_r_square = history.history['val_r_square'][-1]\n",
    "\n",
    "                results = results.append({'n1':n1,'n2':n2,'n3':n3, 'epochs':len(history.history['val_loss']),\n",
    "                              'reg':reg,'val_r2':val_r_square, 'val_nse':val_nse, 'val_mse':val_mse, 'val_loss':val_loss,\n",
    "                                        'val_mae':val_mae, 'val_mape':val_mape}, ignore_index=True)\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_model = model\n",
    "                    best_n1 = n1\n",
    "                    best_n2 = n2\n",
    "                    best_n3 = n3\n",
    "                    best_reg = reg\n",
    "                    best_history = history\n",
    "                    model.save(save_model_path)\n",
    "                    results.to_csv(save_results_path)\n",
    "                    \n",
    "results.to_csv(save_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T19:08:10.637473Z",
     "iopub.status.busy": "2020-09-03T19:08:10.636715Z",
     "iopub.status.idle": "2020-09-03T19:08:10.918258Z",
     "shell.execute_reply": "2020-09-03T19:08:10.917584Z"
    },
    "papermill": {
     "duration": 1.060041,
     "end_time": "2020-09-03T19:08:10.918381",
     "exception": false,
     "start_time": "2020-09-03T19:08:09.858340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T19:08:12.370519Z",
     "iopub.status.busy": "2020-09-03T19:08:12.369382Z",
     "iopub.status.idle": "2020-09-03T19:09:57.271559Z",
     "shell.execute_reply": "2020-09-03T19:09:57.270746Z"
    },
    "papermill": {
     "duration": 105.627151,
     "end_time": "2020-09-03T19:09:57.271707",
     "exception": false,
     "start_time": "2020-09-03T19:08:11.644556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X1_test = test['Discharge1'].tolist()\n",
    "# X2_test= test['Discharge2'].tolist()\n",
    "# X_test = np.stack([X1_test, X2_test], axis=1)\n",
    "# Y_test = test['Depth'].tolist()\n",
    "# T_test = test['Time'].tolist()\n",
    "#predictions = best_model.predict(test['Discharge'].tolist())\n",
    "best_model = tf.keras.models.load_model(save_model_path, custom_objects={\n",
    "                                                                        'loss':custom_loss(calc_grads_inputs), 'NSE':NSE,'r_square':r_square})\n",
    "predictions = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T19:12:39.213568Z",
     "iopub.status.busy": "2020-09-03T19:12:39.212520Z",
     "iopub.status.idle": "2020-09-03T19:12:39.216280Z",
     "shell.execute_reply": "2020-09-03T19:12:39.217164Z"
    },
    "papermill": {
     "duration": 0.812572,
     "end_time": "2020-09-03T19:12:39.217375",
     "exception": false,
     "start_time": "2020-09-03T19:12:38.404803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 15)                90        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                400       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 52        \n",
      "=================================================================\n",
      "Total params: 782\n",
      "Trainable params: 782\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T19:12:40.712903Z",
     "iopub.status.busy": "2020-09-03T19:12:40.711853Z",
     "iopub.status.idle": "2020-09-03T19:12:40.715156Z",
     "shell.execute_reply": "2020-09-03T19:12:40.714458Z"
    },
    "papermill": {
     "duration": 0.783301,
     "end_time": "2020-09-03T19:12:40.715271",
     "exception": false,
     "start_time": "2020-09-03T19:12:39.931970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# results.to_csv('/Users/akhilmehta/Desktop/Ragini_thesis/1point_results_exp1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = best_history.history['loss']\n",
    "val_loss = best_history.history['val_loss']    \n",
    "plt.style.use('seaborn-whitegrid')\n",
    "ax = plt.axes()\n",
    "plt.plot(np.arange(len(train_loss)),train_loss, label ='train loss')\n",
    "plt.plot(np.arange(len(val_loss)),val_loss, label ='validation loss')\n",
    "plt.legend()\n",
    "# plt.xticks(test['Time'].tolist()[::30], rotation = 45)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.savefig('/Users/ge72vep/Desktop/thesis/results/mse_loss_15_5_15.png', dpi=800)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/Users/ge72vep/Desktop/thesis/results/train_mse-15-5-2-HistoryDict', 'wb') as file_pi:\n",
    "        pickle.dump(best_history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T19:12:42.219308Z",
     "iopub.status.busy": "2020-09-03T19:12:42.218523Z",
     "iopub.status.idle": "2020-09-03T19:12:42.682452Z",
     "shell.execute_reply": "2020-09-03T19:12:42.683052Z"
    },
    "papermill": {
     "duration": 1.252156,
     "end_time": "2020-09-03T19:12:42.683212",
     "exception": false,
     "start_time": "2020-09-03T19:12:41.431056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-whitegrid')\n",
    "ax = plt.axes()\n",
    "plt.plot(range(len(predictions[1800::100,0])),predictions[1800::100,0], label ='prediction')\n",
    "plt.plot(range(len(predictions[1800::100,0])),Y_test[1800::100,0], label ='actual')\n",
    "plt.legend()\n",
    "# plt.xticks(range(len(predictions[:,0])), rotation = 45)\n",
    "plt.xlabel('Time * Points')\n",
    "plt.title('Observed and Predicted velocity')\n",
    "# plt.axis([0, 300, 0, 1.25])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving images for Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier = 1\n",
    "tmp_df = test_df[test_df['identifier']==identifier].sort_values(['time','x']).reset_index(drop=True)\n",
    "\n",
    "X_ident = np.array(tmp_df[['x','time', 'q', 'friction_coeff', 'slope']].values.tolist())\n",
    "Y_ident = np.array(tmp_df[['u','h']].values.tolist())\n",
    "\n",
    "predictions_ident = best_model.predict(X_ident)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-whitegrid')\n",
    "for index in range(500):\n",
    "    point = 2*index + 1\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    #ax = plt.axes()\n",
    "    plt.plot(range(len(predictions_ident[index::500,1])),predictions_ident[index::500,1], label ='prediction')\n",
    "    plt.plot(range(len(predictions_ident[index::500,1])),Y_ident[index::500,1], label ='actual')\n",
    "    plt.legend()\n",
    "    # plt.xticks(range(len(predictions[:,0])), rotation = 45)\n",
    "    plt.xlabel('Time')\n",
    "    plt.title('Observed and Predicted height at x='+str(point))\n",
    "    plt.axis([0, 3600, 0, 4])\n",
    "    plt.savefig('/Users/ge72vep/Desktop/thesis/results/images/mse_exp_15_5_15/identifier_'+str(identifier)+'/identifier_' + str(identifier) + '_' + str(point)+'.png', dpi=200)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "img_fns = glob.glob('/Users/ge72vep/Desktop/thesis/results/images/mse_exp_15_5_15/identifier_'+str(identifier)\n",
    "                    +'/*.png')\n",
    "img_nums = [int(fn.split('_')[-1].split('.')[0]) for fn in img_fns]\n",
    "sorted_fns = np.array(img_fns)[np.argsort(img_nums)]\n",
    "\n",
    "img_array = []\n",
    "#video = cv2.VideoWriter('/Users/ge72vep/Desktop/thesis/results/videos/physics_exp_15_5_15_identifer_0.avi',\n",
    " #                       cv2.VideoWriter_fourcc(*\"XVID\"), 30,(width,height))\n",
    "for filename in sorted_fns:\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_array.append(img)\n",
    "    #video.write(img)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "out = cv2.VideoWriter('/Users/ge72vep/Desktop/thesis/results/videos/mse_exp_15_5_15_identifer_'+str(identifier)+'.mp4'\n",
    "                      \n",
    "                      ,cv2.VideoWriter_fourcc(*'FMP4'), 15, size)\n",
    "\n",
    "#cv2.destroyAllWindows()\n",
    "#video.release()\n",
    "\n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier = 2\n",
    "tmp_df = test_df[test_df['identifier']==identifier].sort_values(['time','x']).reset_index(drop=True)\n",
    "\n",
    "X_ident = np.array(tmp_df[['x','time', 'q', 'friction_coeff', 'slope']].values.tolist())\n",
    "Y_ident = np.array(tmp_df[['u','h']].values.tolist())\n",
    "\n",
    "predictions_ident = best_model.predict(X_ident)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-whitegrid')\n",
    "for index in range(360):\n",
    "    point = 2*index + 1\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    #ax = plt.axes()\n",
    "    plt.plot(range(1,1000,2),predictions_ident[10*index*500:(10*index+1) *500 ,1], label ='prediction')\n",
    "    plt.plot(range(1,1000,2),Y_ident[10*index*500:(10*index +1) *500,1], label ='actual')\n",
    "    plt.legend()\n",
    "    # plt.xticks(range(len(predictions[:,0])), rotation = 45)\n",
    "    plt.xlabel('Points')\n",
    "    plt.title('Observed and Predicted time at t='+str(10*index))\n",
    "    plt.axis([0, 1000, 0, 4])\n",
    "    plt.savefig('/Users/ge72vep/Desktop/thesis/results/images/mse_exp_15_5_15/points/identifier_'+str(identifier)+'/identifier_' + str(identifier) + '_' + str(index)+'.png', dpi=200)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "img_fns = glob.glob('/Users/ge72vep/Desktop/thesis/results/images/mse_exp_15_5_15/points/identifier_'+str(identifier)\n",
    "                    +'/*.png')\n",
    "img_nums = [int(fn.split('_')[-1].split('.')[0]) for fn in img_fns]\n",
    "sorted_fns = np.array(img_fns)[np.argsort(img_nums)]\n",
    "\n",
    "img_array = []\n",
    "#video = cv2.VideoWriter('/Users/ge72vep/Desktop/thesis/results/videos/physics_exp_15_5_15_identifer_0.avi',\n",
    " #                       cv2.VideoWriter_fourcc(*\"XVID\"), 30,(width,height))\n",
    "for filename in sorted_fns:\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_array.append(img)\n",
    "    #video.write(img)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "out = cv2.VideoWriter('/Users/ge72vep/Desktop/thesis/results/videos/points_mse_15_5_15_identifer_'+str(identifier)+'.mp4'\n",
    "                      \n",
    "                      ,cv2.VideoWriter_fourcc(*'FMP4'), 15, size)\n",
    "\n",
    "#cv2.destroyAllWindows()\n",
    "#video.release()\n",
    "\n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model(save_model_path, custom_objects={\n",
    "                                                                        'NSE':NSE,'r_square':r_square})\n",
    "test_results = pd.DataFrame(columns=['identifier', 'exp_name',  'q_max', 'slope', 'friction_coeff','u_nse','u_mse','u_r2', 'h_nse', 'h_mse',\n",
    "                               'h_r2', 'avg_nse', 'avg_r2', 'avg_mse'])\n",
    "\n",
    "if not os.path.exists(os.path.join(BASE_DIR_PATH, metrics_dir)):\n",
    "    os.makedirs(os.path.join(BASE_DIR_PATH, metrics_dir))\n",
    "for identifier in range(len(test_df['identifier'].unique())):\n",
    "    tmp_df = test_df[test_df['identifier']==identifier].sort_values(['time','x']).reset_index(drop=True)\n",
    "    X_ident = np.array(tmp_df[['x','time', 'q', 'friction_coeff', 'slope']].values.tolist())\n",
    "    Y_ident = tf.convert_to_tensor(np.array(tmp_df[['u','h']].values.tolist()).astype(np.float32))\n",
    "    predictions_ident = tf.convert_to_tensor(best_model.predict(X_ident))\n",
    "    \n",
    "    s = tmp_df['slope'].unique()[0]\n",
    "    q_max = tmp_df['q'].max()\n",
    "    f_coeff = tmp_df['friction_coeff'].unique()[0]\n",
    "\n",
    "    u_nse = K.eval(NSE(Y_ident[:,0], predictions_ident[:,0]))\n",
    "    u_r2 = K.eval(r_square(Y_ident[:,0], predictions_ident[:,0]))\n",
    "    u_mse = K.get_value(tf.keras.metrics.mse(Y_ident[:,0], predictions_ident[:,0]))\n",
    "\n",
    "    h_nse = K.eval(NSE(Y_ident[:,1], predictions_ident[:,1]))\n",
    "    h_r2 = K.eval(r_square(Y_ident[:,1], predictions_ident[:,1]))\n",
    "    h_mse = K.get_value(tf.keras.metrics.mse(Y_ident[:,1], predictions_ident[:,1]))\n",
    "\n",
    "    avg_nse = (u_nse + h_nse)/2.0\n",
    "    avg_r2 = (u_r2 + h_r2)/2.0\n",
    "    avg_mse = (u_mse + h_mse)/2.0\n",
    "    \n",
    "    test_results = test_results.append({'identifier':identifier, 'exp_name':EXP_NAME, 'q_max' : q_max, 'slope' : s, 'friction_coeff':f_coeff,\n",
    "                                        'u_nse' : u_nse,'u_mse': u_mse,'u_r2':u_r2, 'h_nse':h_nse, 'h_mse':h_mse,\n",
    "                               'h_r2':h_r2, 'avg_nse':avg_nse, 'avg_r2':avg_r2, 'avg_mse':avg_mse}, ignore_index=True)\n",
    "    \n",
    "    \n",
    "\n",
    "test_results.to_csv(save_test_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 1095.738968,
   "end_time": "2020-09-03T19:12:53.052539",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-03T18:54:37.313571",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
