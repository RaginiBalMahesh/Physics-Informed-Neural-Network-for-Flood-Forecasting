{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PINN training and validation file for custom loss function weightage (penalty) analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:54:43.700689Z",
     "iopub.status.busy": "2020-09-03T18:54:43.699893Z",
     "iopub.status.idle": "2020-09-03T18:54:51.337199Z",
     "shell.execute_reply": "2020-09-03T18:54:51.336347Z"
    },
    "papermill": {
     "duration": 7.66074,
     "end_time": "2020-09-03T18:54:51.337335",
     "exception": false,
     "start_time": "2020-09-03T18:54:43.676595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "# from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# %load_ext tensorboard\n",
    "# import tensorboard\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:54:51.362612Z",
     "iopub.status.busy": "2020-09-03T18:54:51.361681Z",
     "iopub.status.idle": "2020-09-03T18:54:51.364781Z",
     "shell.execute_reply": "2020-09-03T18:54:51.364047Z"
    },
    "papermill": {
     "duration": 0.017802,
     "end_time": "2020-09-03T18:54:51.364901",
     "exception": false,
     "start_time": "2020-09-03T18:54:51.347099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008631,
     "end_time": "2020-09-03T18:54:51.384383",
     "exception": false,
     "start_time": "2020-09-03T18:54:51.375752",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR_PATH = '/Users/ge72vep/Desktop/thesis/'\n",
    "DATA_PATH = 'Data/Model_8/'\n",
    "MODEL_PATH = 'models/model_8_w_1sec_batch1.h5' ######## Check the data path ######## \n",
    "IMAGES_PATH = 'results/images/'\n",
    "VIDEOS_PATH = 'results/videos/'\n",
    "EXP_NAME = 'physics_exp_1sec_M8_w_batch1' ######## Check file name ######## \n",
    "VIDEO_NAME = 'phy_1sec_M8_w_batch1'  ######## Check file name ######## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = os.path.join(BASE_DIR_PATH, DATA_PATH)\n",
    "save_model_path = os.path.join(BASE_DIR_PATH, MODEL_PATH)\n",
    "save_images_path = os.path.join(BASE_DIR_PATH, IMAGES_PATH, EXP_NAME)\n",
    "save_video_path = os.path.join(BASE_DIR_PATH, VIDEOS_PATH, VIDEO_NAME)\n",
    "save_results_path = os.path.join(BASE_DIR_PATH, 'models', EXP_NAME+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.00855,
     "end_time": "2020-09-03T18:54:51.428366",
     "exception": false,
     "start_time": "2020-09-03T18:54:51.419816",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "#### Loading dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:54:51.456883Z",
     "iopub.status.busy": "2020-09-03T18:54:51.456152Z",
     "iopub.status.idle": "2020-09-03T18:55:20.110167Z",
     "shell.execute_reply": "2020-09-03T18:55:20.109464Z"
    },
    "papermill": {
     "duration": 28.673092,
     "end_time": "2020-09-03T18:55:20.110292",
     "exception": false,
     "start_time": "2020-09-03T18:54:51.437200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(PATH_TO_DATA, 'train.csv'))\n",
    "val_df = pd.read_csv(os.path.join(PATH_TO_DATA, 'val.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sort_values(['identifier','x','time']).reset_index(drop=True)\n",
    "val_df = val_df.sort_values(['identifier','x','time']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:55:20.590412Z",
     "iopub.status.busy": "2020-09-03T18:55:20.589341Z",
     "iopub.status.idle": "2020-09-03T18:56:42.362580Z",
     "shell.execute_reply": "2020-09-03T18:56:42.361758Z"
    },
    "papermill": {
     "duration": 82.242915,
     "end_time": "2020-09-03T18:56:42.362715",
     "exception": false,
     "start_time": "2020-09-03T18:55:20.119800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = np.array(train_df[['x','time', 'q', 'friction_coeff', 'slope']].values.tolist())\n",
    "X_val = np.array(val_df[['x','time', 'q', 'friction_coeff', 'slope']].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:57:21.606283Z",
     "iopub.status.busy": "2020-09-03T18:56:59.759759Z",
     "iopub.status.idle": "2020-09-03T18:57:37.604965Z",
     "shell.execute_reply": "2020-09-03T18:57:37.604326Z"
    },
    "papermill": {
     "duration": 55.232753,
     "end_time": "2020-09-03T18:57:37.605097",
     "exception": false,
     "start_time": "2020-09-03T18:56:42.372344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y_train = np.array(train_df[['u','h']].values.tolist())\n",
    "Y_val = np.array(val_df[['u','h']].values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008895,
     "end_time": "2020-09-03T18:57:37.623182",
     "exception": false,
     "start_time": "2020-09-03T18:57:37.614287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:57:37.646495Z",
     "iopub.status.busy": "2020-09-03T18:57:37.645744Z",
     "iopub.status.idle": "2020-09-03T18:57:37.649313Z",
     "shell.execute_reply": "2020-09-03T18:57:37.648580Z"
    },
    "papermill": {
     "duration": 0.017209,
     "end_time": "2020-09-03T18:57:37.649445",
     "exception": false,
     "start_time": "2020-09-03T18:57:37.632236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs= 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008778,
     "end_time": "2020-09-03T18:57:37.667128",
     "exception": false,
     "start_time": "2020-09-03T18:57:37.658350",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Model  with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:57:37.690242Z",
     "iopub.status.busy": "2020-09-03T18:57:37.689541Z",
     "iopub.status.idle": "2020-09-03T18:57:37.692914Z",
     "shell.execute_reply": "2020-09-03T18:57:37.692342Z"
    },
    "papermill": {
     "duration": 0.017064,
     "end_time": "2020-09-03T18:57:37.693031",
     "exception": false,
     "start_time": "2020-09-03T18:57:37.675967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_val_loss = np.inf\n",
    "best_model = -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:57:37.723239Z",
     "iopub.status.busy": "2020-09-03T18:57:37.722249Z",
     "iopub.status.idle": "2020-09-03T18:57:37.725716Z",
     "shell.execute_reply": "2020-09-03T18:57:37.724996Z"
    },
    "papermill": {
     "duration": 0.023284,
     "end_time": "2020-09-03T18:57:37.725823",
     "exception": false,
     "start_time": "2020-09-03T18:57:37.702539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['n1','n2','n3', 'epochs', 'reg',\n",
    "                               'val_r2', 'val_nse', 'val_mse', 'val_mae', 'val_mape'])\n",
    "layer_1_neurons = np.arange(5,26,10) ######## Check the number of neurons ########\n",
    "layer_2_neurons = np.arange(5,26,10) ######## Check the number of neurons ########\n",
    "layer_3_neurons = np.arange(5,26,10) ######## Check the number of neurons ########\n",
    "reg_consts = [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weightage to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightage = [1,2,3,4]  ######## Check the weight penalties ########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:57:37.752901Z",
     "iopub.status.busy": "2020-09-03T18:57:37.752081Z",
     "iopub.status.idle": "2020-09-03T18:57:37.755228Z",
     "shell.execute_reply": "2020-09-03T18:57:37.754686Z"
    },
    "papermill": {
     "duration": 0.020527,
     "end_time": "2020-09-03T18:57:37.755338",
     "exception": false,
     "start_time": "2020-09-03T18:57:37.734811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def r_square(y_true, y_pred):\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    mx = K.mean(x, axis=0)\n",
    "    my = K.mean(y, axis=0)\n",
    "    xm, ym = x - mx, y - my\n",
    "    r_num = K.square(K.sum(xm * ym))\n",
    "    x_square_sum = K.sum(xm * xm)\n",
    "    y_square_sum = K.sum(ym * ym)\n",
    "    r_den = (x_square_sum * y_square_sum) + K.epsilon()\n",
    "    \n",
    "    r = r_num / r_den\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:57:37.781819Z",
     "iopub.status.busy": "2020-09-03T18:57:37.780806Z",
     "iopub.status.idle": "2020-09-03T18:57:37.783340Z",
     "shell.execute_reply": "2020-09-03T18:57:37.783923Z"
    },
    "papermill": {
     "duration": 0.019312,
     "end_time": "2020-09-03T18:57:37.784065",
     "exception": false,
     "start_time": "2020-09-03T18:57:37.764753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def NSE(y_true, y_pred):\n",
    "\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    y_true = K.flatten(y_true)\n",
    "\n",
    "    \n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom loss function with weight penalty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:57:37.814038Z",
     "iopub.status.busy": "2020-09-03T18:57:37.813231Z",
     "iopub.status.idle": "2020-09-03T18:57:37.816289Z",
     "shell.execute_reply": "2020-09-03T18:57:37.815740Z"
    },
    "papermill": {
     "duration": 0.023217,
     "end_time": "2020-09-03T18:57:37.816410",
     "exception": false,
     "start_time": "2020-09-03T18:57:37.793193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_loss(grads_inputs, weight):\n",
    "    du_dx, du_dt, dh_dx, fric_coeff, slope = grads_inputs[:,0], grads_inputs[:,1], grads_inputs[:,2], grads_inputs[:,3], grads_inputs[:,4]\n",
    "    g = K.constant(9.8)\n",
    "    w =  K.constant(weight)\n",
    "    # Create a loss function that adds the MSE loss to the mean of all squared activations of a specific layer\n",
    "    def loss(y_true,y_pred):\n",
    "        loss_saint_venant = du_dt + y_pred[:,0] * du_dx + g*dh_dx + g*slope + g*K.square(fric_coeff) * K.square(y_true[:,0])/(K.pow(y_true[:,1], 4/3) + K.epsilon())\n",
    "        l = K.mean(K.square(loss_saint_venant))\n",
    "#         \n",
    "        return w*l+ K.sum(K.mean(K.square(y_pred - y_true), axis=0))\n",
    "   \n",
    "    # Return a function\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T18:57:37.859913Z",
     "iopub.status.busy": "2020-09-03T18:57:37.858948Z",
     "iopub.status.idle": "2020-09-03T19:08:09.137913Z",
     "shell.execute_reply": "2020-09-03T19:08:09.137246Z"
    },
    "papermill": {
     "duration": 631.312345,
     "end_time": "2020-09-03T19:08:09.138043",
     "exception": false,
     "start_time": "2020-09-03T18:57:37.825698",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5 5 0\n",
      "WARNING:tensorflow:From D:\\Users\\ge72vep\\.conda\\envs\\thesis\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Train on 12002500 samples, validate on 2885500 samples\n",
      "Epoch 1/15\n",
      "12002500/12002500 [==============================] - 330s 28us/sample - loss: 16.3147 - mape: 50.5862 - mae: 0.5722 - mse: 8.1541 - NSE: -5.7128 - r_square: 0.6599 - val_loss: 0.5252 - val_mape: 29.8980 - val_mae: 0.3882 - val_mse: 0.2584 - val_NSE: 0.7459 - val_r_square: 0.7746mae: 0.6605 - mse: 12.1266 - NSE: -8.9842 - r_ - ETA: 1:28 - loss: 23.4036 - mape: 58.9790 - mae: 0.6519 - mse: 11.6983 - N - ETA: - ETA: 1:21 - loss: 22.5437 - mape: 58.04 - ETA: 1:17 - loss: 22.1546 - map - ETA: 1:12 - loss: 21.6991 - ETA: 42s - loss: 19.0366 - mape: 53.8830 - mae: 0.6042 - mse: 9.5 - ETA: 4s - loss: 16.5913 - mape: 50.9222 - mae: \n",
      "Epoch 2/15\n",
      "12002500/12002500 [==============================] - 324s 27us/sample - loss: 0.3436 - mape: 25.8977 - mae: 0.3153 - mse: 0.1687 - NSE: 0.8620 - r_square: 0.8658 - val_loss: 0.2909 - val_mape: 23.0242 - val_mae: 0.2929 - val_mse: 0.1413 - val_NSE: 0.8608 - val_r_square: 0.8736\n",
      "Epoch 3/15\n",
      "12002500/12002500 [==============================] - 329s 27us/sample - loss: 0.1979 - mape: 18.8533 - mae: 0.2290 - mse: 0.0959 - NSE: 0.9216 - r_square: 0.9268 - val_loss: 0.2077 - val_mape: 21.1555 - val_mae: 0.2484 - val_mse: 0.0997 - val_NSE: 0.9019 - val_r_square: 0.9051\n",
      "Epoch 4/15\n",
      "12002500/12002500 [==============================] - 327s 27us/sample - loss: 0.1601 - mape: 17.2457 - mae: 0.2063 - mse: 0.0770 - NSE: 0.9370 - r_square: 0.9419 - val_loss: 0.2567 - val_mape: 19.5328 - val_mae: 0.2617 - val_mse: 0.1242 - val_NSE: 0.8776 - val_r_square: 0.9100\n",
      "Epoch 5/15\n",
      "12002500/12002500 [==============================] - 336s 28us/sample - loss: 0.1195 - mape: 14.9844 - mae: 0.1752 - mse: 0.0567 - NSE: 0.9536 - r_square: 0.9583 - val_loss: 0.1562 - val_mape: 14.9639 - val_mae: 0.2030 - val_mse: 0.0740 - val_NSE: 0.9273 - val_r_square: 0.9369\n",
      "Epoch 6/15\n",
      "12002500/12002500 [==============================] - 339s 28us/sample - loss: 0.1136 - mape: 14.4481 - mae: 0.1698 - mse: 0.0538 - NSE: 0.9560 - r_square: 0.9603 - val_loss: 0.1160 - val_mape: 13.5465 - val_mae: 0.1780 - val_mse: 0.0539 - val_NSE: 0.9470 - val_r_square: 0.9506\n",
      "Epoch 7/15\n",
      "12002500/12002500 [==============================] - 328s 27us/sample - loss: 0.1096 - mape: 14.1805 - mae: 0.1665 - mse: 0.0517 - NSE: 0.9577 - r_square: 0.9615 - val_loss: 0.1286 - val_mape: 14.1408 - val_mae: 0.1876 - val_mse: 0.0602 - val_NSE: 0.9408 - val_r_square: 0.9502\n",
      "Epoch 8/15\n",
      "12002500/12002500 [==============================] - 340s 28us/sample - loss: 0.1076 - mape: 14.0674 - mae: 0.1649 - mse: 0.0507 - NSE: 0.9584 - r_square: 0.9622 - val_loss: 0.1711 - val_mape: 16.0673 - val_mae: 0.2155 - val_mse: 0.0814 - val_NSE: 0.9198 - val_r_square: 0.9416\n",
      "5 5 15 0\n",
      "Train on 12002500 samples, validate on 2885500 samples\n",
      "Epoch 1/15\n",
      "12002500/12002500 [==============================] - 352s 29us/sample - loss: 3.1787 - mape: 34.8795 - mae: 0.4330 - mse: 1.5841 - NSE: -0.3089 - r_square: 0.7563 - val_loss: 0.6624 - val_mape: 27.9262 - val_mae: 0.4034 - val_mse: 0.3269 - val_NSE: 0.6781 - val_r_square: 0.7123\n",
      "Epoch 2/15\n",
      "12002500/12002500 [==============================] - 355s 30us/sample - loss: 0.3256 - mape: 23.6871 - mae: 0.3004 - mse: 0.1597 - NSE: 0.8694 - r_square: 0.8713 - val_loss: 0.6600 - val_mape: 32.2238 - val_mae: 0.4310 - val_mse: 0.3257 - val_NSE: 0.6791 - val_r_square: 0.6946\n",
      "Epoch 3/15\n",
      "12002500/12002500 [==============================] - 357s 30us/sample - loss: 0.2956 - mape: 22.6279 - mae: 0.2870 - mse: 0.1447 - NSE: 0.8816 - r_square: 0.8833 - val_loss: 0.5787 - val_mape: 32.2185 - val_mae: 0.4215 - val_mse: 0.2851 - val_NSE: 0.7191 - val_r_square: 0.7257\n",
      "Epoch 4/15\n",
      "12002500/12002500 [==============================] - 349s 29us/sample - loss: 0.2833 - mape: 22.1462 - mae: 0.2809 - mse: 0.1386 - NSE: 0.8866 - r_square: 0.8883 - val_loss: 0.6810 - val_mape: 30.1565 - val_mae: 0.4222 - val_mse: 0.3363 - val_NSE: 0.6687 - val_r_square: 0.7015\n",
      "Epoch 5/15\n",
      "12002500/12002500 [==============================] - 363s 30us/sample - loss: 0.2759 - mape: 21.8669 - mae: 0.2768 - mse: 0.1349 - NSE: 0.8897 - r_square: 0.8913 - val_loss: 0.7167 - val_mape: 32.3730 - val_mae: 0.4473 - val_mse: 0.3542 - val_NSE: 0.6510 - val_r_square: 0.6761\n",
      "5 5 25 0\n",
      "Train on 12002500 samples, validate on 2885500 samples\n",
      "Epoch 1/15\n",
      "12002500/12002500 [==============================] - 376s 31us/sample - loss: 1.6436 - mape: 33.7967 - mae: 0.4227 - mse: 0.8178 - NSE: 0.3257 - r_square: 0.7666 - val_loss: 0.3759 - val_mape: 23.7357 - val_mae: 0.3236 - val_mse: 0.1837 - val_NSE: 0.8196 - val_r_square: 0.8333\n",
      "Epoch 2/15\n",
      "12002500/12002500 [==============================] - 372s 31us/sample - loss: 0.3221 - mape: 23.4473 - mae: 0.3060 - mse: 0.1580 - NSE: 0.8707 - r_square: 0.8751 - val_loss: 0.5976 - val_mape: 29.8104 - val_mae: 0.4102 - val_mse: 0.2946 - val_NSE: 0.7103 - val_r_square: 0.7850\n",
      "Epoch 3/15\n",
      "12002500/12002500 [==============================] - 373s 31us/sample - loss: 0.2655 - mape: 20.9515 - mae: 0.2710 - mse: 0.1297 - NSE: 0.8938 - r_square: 0.8975 - val_loss: 0.6102 - val_mape: 27.0152 - val_mae: 0.4124 - val_mse: 0.3009 - val_NSE: 0.7038 - val_r_square: 0.7255\n",
      "5 15 5 0\n",
      "Train on 12002500 samples, validate on 2885500 samples\n",
      "Epoch 1/15\n",
      "12002500/12002500 [==============================] - 336s 28us/sample - loss: 3.0098 - mape: 42.5607 - mae: 0.5199 - mse: 1.5000 - NSE: -0.2394 - r_square: 0.6718 - val_loss: 0.5078 - val_mape: 26.3036 - val_mae: 0.3698 - val_mse: 0.2493 - val_NSE: 0.7545 - val_r_square: 0.7782\n",
      "Epoch 2/15\n",
      "12002500/12002500 [==============================] - 342s 29us/sample - loss: 0.3626 - mape: 25.1995 - mae: 0.3274 - mse: 0.1781 - NSE: 0.8544 - r_square: 0.8610 - val_loss: 0.4425 - val_mape: 26.3369 - val_mae: 0.3581 - val_mse: 0.2171 - val_NSE: 0.7864 - val_r_square: 0.7913\n",
      "Epoch 3/15\n",
      "12002500/12002500 [==============================] - 343s 29us/sample - loss: 0.1981 - mape: 18.8138 - mae: 0.2345 - mse: 0.0960 - NSE: 0.9214 - r_square: 0.9256 - val_loss: 0.2597 - val_mape: 18.3373 - val_mae: 0.2602 - val_mse: 0.1256 - val_NSE: 0.8765 - val_r_square: 0.9113\n",
      "Epoch 4/15\n",
      "12002500/12002500 [==============================] - 350s 29us/sample - loss: 0.0782 - mape: 11.4585 - mae: 0.1392 - mse: 0.0360 - NSE: 0.9705 - r_square: 0.9750 - val_loss: 0.2208 - val_mape: 15.3305 - val_mae: 0.2325 - val_mse: 0.1062 - val_NSE: 0.8956 - val_r_square: 0.9219\n",
      "Epoch 5/15\n",
      "12002500/12002500 [==============================] - 342s 28us/sample - loss: 0.0728 - mape: 10.9413 - mae: 0.1334 - mse: 0.0333 - NSE: 0.9727 - r_square: 0.9767 - val_loss: 0.2022 - val_mape: 14.2087 - val_mae: 0.2210 - val_mse: 0.0969 - val_NSE: 0.9047 - val_r_square: 0.9262\n",
      "Epoch 6/15\n",
      "12002500/12002500 [==============================] - 328s 27us/sample - loss: 0.0680 - mape: 10.4893 - mae: 0.1289 - mse: 0.0309 - NSE: 0.9747 - r_square: 0.9781 - val_loss: 0.1945 - val_mape: 13.4227 - val_mae: 0.2198 - val_mse: 0.0931 - val_NSE: 0.9084 - val_r_square: 0.9300\n",
      "Epoch 7/15\n",
      "12002500/12002500 [==============================] - 333s 28us/sample - loss: 0.0644 - mape: 10.2095 - mae: 0.1256 - mse: 0.0291 - NSE: 0.9762 - r_square: 0.9793 - val_loss: 0.2138 - val_mape: 14.2380 - val_mae: 0.2261 - val_mse: 0.1027 - val_NSE: 0.8990 - val_r_square: 0.9241\n",
      "Epoch 8/15\n",
      "12002500/12002500 [==============================] - 343s 29us/sample - loss: 0.0618 - mape: 9.9833 - mae: 0.1230 - mse: 0.0278 - NSE: 0.9772 - r_square: 0.9801 - val_loss: 0.1982 - val_mape: 14.9366 - val_mae: 0.2229 - val_mse: 0.0949 - val_NSE: 0.9067 - val_r_square: 0.9284\n",
      "5 15 15 0\n",
      "Train on 12002500 samples, validate on 2885500 samples\n",
      "Epoch 1/15\n",
      "12002500/12002500 [==============================] - 414s 35us/sample - loss: 1.1596 - mape: 34.4720 - mae: 0.4273 - mse: 0.5765 - NSE: 0.5227 - r_square: 0.7934 - val_loss: 0.4913 - val_mape: 25.1514 - val_mae: 0.3656 - val_mse: 0.2415 - val_NSE: 0.7625 - val_r_square: 0.7976\n",
      "Epoch 2/15\n",
      "12002500/12002500 [==============================] - 418s 35us/sample - loss: 0.1991 - mape: 18.6902 - mae: 0.2362 - mse: 0.0965 - NSE: 0.9210 - r_square: 0.9299 - val_loss: 0.1945 - val_mape: 15.9929 - val_mae: 0.2314 - val_mse: 0.0930 - val_NSE: 0.9085 - val_r_square: 0.9278\n",
      "Epoch 3/15\n",
      "12002500/12002500 [==============================] - 421s 35us/sample - loss: 0.0822 - mape: 11.6215 - mae: 0.1453 - mse: 0.0380 - NSE: 0.9689 - r_square: 0.9746 - val_loss: 0.2758 - val_mape: 18.4943 - val_mae: 0.2626 - val_mse: 0.1337 - val_NSE: 0.8685 - val_r_square: 0.9290\n",
      "Epoch 4/15\n",
      "12002500/12002500 [==============================] - 421s 35us/sample - loss: 0.0576 - mape: 9.4638 - mae: 0.1190 - mse: 0.0257 - NSE: 0.9789 - r_square: 0.9827 - val_loss: 0.2678 - val_mape: 16.4093 - val_mae: 0.2443 - val_mse: 0.1297 - val_NSE: 0.8724 - val_r_square: 0.9207\n",
      "5 15 25 0\n",
      "Train on 12002500 samples, validate on 2885500 samples\n",
      "Epoch 1/15\n",
      "12002500/12002500 [==============================] - 452s 38us/sample - loss: 1.4088 - mape: 35.8025 - mae: 0.4345 - mse: 0.7007 - NSE: 0.4232 - r_square: 0.7535 - val_loss: 0.8032 - val_mape: 31.5146 - val_mae: 0.4732 - val_mse: 0.3974 - val_NSE: 0.6090 - val_r_square: 0.6393ape: 36.2040 - mae: 0.4391 - mse: 0.7191 - NSE: 0.4080 - r_square:  - ETA: 12s - loss: 1.4442 - mape: 36.1880 - mae: 0.4389 - mse: 0.7184 - NSE: 0.4086 - r_square: 0.749 - ETA: 12s - loss: 1.4439 - mape: 36.1855 - mae: 0.4389 - mse: 0.7182 - NSE: 0.4087 - r_square: 0.74 - ETA: 12s - loss: 1.4435 - mape: 36.1803 - mae: 0.4388 - mse: 0.7180 - NSE: 0.4089 - r_square:  - ETA: 11s - loss: 1.4420 - mape: 36.1657 - mae: 0.4386 \n",
      "Epoch 2/15\n",
      "12002500/12002500 [==============================] - 430s 36us/sample - loss: 0.3053 - mape: 22.9666 - mae: 0.2884 - mse: 0.1495 - NSE: 0.8775 - r_square: 0.8797 - val_loss: 0.7697 - val_mape: 33.6191 - val_mae: 0.4718 - val_mse: 0.3806 - val_NSE: 0.6254 - val_r_square: 0.6415\n",
      "Epoch 3/15\n",
      "12002500/12002500 [==============================] - 435s 36us/sample - loss: 0.2902 - mape: 22.1337 - mae: 0.2807 - mse: 0.1420 - NSE: 0.8837 - r_square: 0.8854 - val_loss: 0.7841 - val_mape: 33.1579 - val_mae: 0.4761 - val_mse: 0.3879 - val_NSE: 0.6182 - val_r_square: 0.6412\n",
      "Epoch 4/15\n",
      "12002500/12002500 [==============================] - 441s 37us/sample - loss: 0.2764 - mape: 21.3077 - mae: 0.2714 - mse: 0.1351 - NSE: 0.8894 - r_square: 0.8907 - val_loss: 0.8351 - val_mape: 31.7554 - val_mae: 0.4750 - val_mse: 0.4134 - val_NSE: 0.5931 - val_r_square: 0.6221\n",
      "5 25 5 0\n",
      "Train on 12002500 samples, validate on 2885500 samples\n",
      "Epoch 1/15\n",
      "12002500/12002500 [==============================] - 404s 34us/sample - loss: 1.4301 - mape: 48.9023 - mae: 0.6191 - mse: 0.7120 - NSE: 0.4222 - r_square: 0.4406 - val_loss: 0.9153 - val_mape: 44.5698 - val_mae: 0.5136 - val_mse: 0.4535 - val_NSE: 0.5550 - val_r_square: 0.5661\n",
      "Epoch 2/15\n",
      "12002500/12002500 [==============================] - 398s 33us/sample - loss: 1.3064 - mape: 46.0873 - mae: 0.5955 - mse: 0.6501 - NSE: 0.4721 - r_square: 0.4728 - val_loss: 0.8138 - val_mape: 38.2603 - val_mae: 0.4782 - val_mse: 0.4027 - val_NSE: 0.6051 - val_r_square: 0.6022\n",
      "Epoch 3/15\n",
      "12002500/12002500 [==============================] - 396s 33us/sample - loss: 1.2976 - mape: 45.8015 - mae: 0.5944 - mse: 0.6458 - NSE: 0.4755 - r_square: 0.4758 - val_loss: 0.9517 - val_mape: 46.0664 - val_mae: 0.5388 - val_mse: 0.4717 - val_NSE: 0.5367 - val_r_square: 0.5515\n",
      "Epoch 4/15\n",
      "12002500/12002500 [==============================] - 386s 32us/sample - loss: 1.2934 - mape: 45.6715 - mae: 0.5941 - mse: 0.6436 - NSE: 0.4773 - r_square: 0.4771 - val_loss: 0.9900 - val_mape: 48.2797 - val_mae: 0.5481 - val_mse: 0.4909 - val_NSE: 0.5178 - val_r_square: 0.5463\n",
      "5 25 15 0\n",
      "Train on 12002500 samples, validate on 2885500 samples\n",
      "Epoch 1/15\n",
      "12002500/12002500 [==============================] - 442s 37us/sample - loss: 3.2997 - mape: 32.6583 - mae: 0.3986 - mse: 1.6441 - NSE: -0.3236 - r_square: 0.7876 - val_loss: 0.6338 - val_mape: 29.1859 - val_mae: 0.4218 - val_mse: 0.3125 - val_NSE: 0.6923 - val_r_square: 0.7033\n",
      "Epoch 2/15\n",
      "12002500/12002500 [==============================] - 440s 37us/sample - loss: 0.2142 - mape: 18.8930 - mae: 0.2450 - mse: 0.1040 - NSE: 0.9148 - r_square: 0.9177 - val_loss: 0.5594 - val_mape: 25.2731 - val_mae: 0.3919 - val_mse: 0.2754 - val_NSE: 0.7289 - val_r_square: 0.7522\n",
      "Epoch 3/15\n",
      "12002500/12002500 [==============================] - 450s 38us/sample - loss: 0.1783 - mape: 16.9359 - mae: 0.2230 - mse: 0.0860 - NSE: 0.9295 - r_square: 0.9320 - val_loss: 0.5736 - val_mape: 28.7468 - val_mae: 0.3971 - val_mse: 0.2826 - val_NSE: 0.7219 - val_r_square: 0.7414\n",
      "Epoch 4/15\n",
      "12002500/12002500 [==============================] - 440s 37us/sample - loss: 0.1543 - mape: 15.5908 - mae: 0.2052 - mse: 0.0740 - NSE: 0.9394 - r_square: 0.9415 - val_loss: 0.4176 - val_mape: 23.0376 - val_mae: 0.3268 - val_mse: 0.2046 - val_NSE: 0.7983 - val_r_square: 0.8175\n",
      "Epoch 5/15\n",
      "12002500/12002500 [==============================] - 446s 37us/sample - loss: 0.0701 - mape: 9.9507 - mae: 0.1248 - mse: 0.0319 - NSE: 0.9739 - r_square: 0.9777 - val_loss: 0.1778 - val_mape: 14.7527 - val_mae: 0.2154 - val_mse: 0.0847 - val_NSE: 0.9165 - val_r_square: 0.9267\n",
      "Epoch 6/15\n",
      "12002500/12002500 [==============================] - 434s 36us/sample - loss: 0.0490 - mape: 7.7444 - mae: 0.0983 - mse: 0.0214 - NSE: 0.9826 - r_square: 0.9856 - val_loss: 0.1794 - val_mape: 15.1647 - val_mae: 0.2245 - val_mse: 0.0855 - val_NSE: 0.9158 - val_r_square: 0.9276\n",
      "Epoch 7/15\n",
      "12002500/12002500 [==============================] - 435s 36us/sample - loss: 0.0430 - mape: 7.2211 - mae: 0.0908 - mse: 0.0184 - NSE: 0.9849 - r_square: 0.9875 - val_loss: 0.1948 - val_mape: 15.2371 - val_mae: 0.2278 - val_mse: 0.0932 - val_NSE: 0.9082 - val_r_square: 0.9218\n",
      "5 25 25 0\n",
      "Train on 12002500 samples, validate on 2885500 samples\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12002500/12002500 [==============================] - 452s 38us/sample - loss: 1.4252 - mape: 31.8074 - mae: 0.3857 - mse: 0.7085 - NSE: 0.4187 - r_square: 0.8172 - val_loss: 0.6837 - val_mape: 30.9897 - val_mae: 0.4339 - val_mse: 0.3377 - val_NSE: 0.6672 - val_r_square: 0.6866\n",
      "Epoch 2/15\n",
      "12002500/12002500 [==============================] - 451s 38us/sample - loss: 0.1975 - mape: 18.1754 - mae: 0.2341 - mse: 0.0957 - NSE: 0.9217 - r_square: 0.9245 - val_loss: 0.6502 - val_mape: 33.2051 - val_mae: 0.4416 - val_mse: 0.3209 - val_NSE: 0.6838 - val_r_square: 0.6916\n",
      "Epoch 3/15\n",
      "12002500/12002500 [==============================] - 458s 38us/sample - loss: 0.1150 - mape: 13.5103 - mae: 0.1709 - mse: 0.0544 - NSE: 0.9554 - r_square: 0.9586 - val_loss: 0.2128 - val_mape: 18.2431 - val_mae: 0.2445 - val_mse: 0.1022 - val_NSE: 0.8993 - val_r_square: 0.9168\n",
      "Epoch 4/15\n",
      "12002500/12002500 [==============================] - 450s 37us/sample - loss: 0.0480 - mape: 8.1945 - mae: 0.1028 - mse: 0.0209 - NSE: 0.9830 - r_square: 0.9864 - val_loss: 0.3670 - val_mape: 19.8631 - val_mae: 0.2937 - val_mse: 0.1793 - val_NSE: 0.8234 - val_r_square: 0.8623\n",
      "Epoch 5/15\n",
      "12002500/12002500 [==============================] - 438s 36us/sample - loss: 0.0396 - mape: 7.1880 - mae: 0.0893 - mse: 0.0167 - NSE: 0.9861 - r_square: 0.9889 - val_loss: 0.1847 - val_mape: 15.2733 - val_mae: 0.2247 - val_mse: 0.0881 - val_NSE: 0.9131 - val_r_square: 0.9284 mape: 7.2213 - mae: 0.0898 - mse: 0.0168 - NSE: 0.9861 - r_sq - ETA: 22s - loss: 0.0399 - mape: 7.2188 - mae: 0.0897 - mse: 0.0168 - NSE: 0.9861 - r_square: 0. - ETA: 22s - loss: 0.0398 - mape: 7.2179 - mae: 0.0897 - mse: 0.0168 - NSE: 0.9861 -  - ETA: 21s - loss: 0.0399 - mape: 7.2214 - mae: 0.0898 - mse: 0.0168 - NSE: 0.9860 - r_square:  - ETA: 21s - loss: 0.0399 - mape: 7.2225 - mae: 0.0898 - mse: 0.0168 - NSE: 0.986 - ETA: 20s - loss: 0.0399 - mape: 7.2186 - mae: 0.0897 - mse: 0.0168 - NSE: 0.9861 - r_square - E\n",
      "Epoch 6/15\n",
      "12002500/12002500 [==============================] - 443s 37us/sample - loss: 0.0364 - mape: 6.7297 - mae: 0.0827 - mse: 0.0151 - NSE: 0.9875 - r_square: 0.9900 - val_loss: 0.2137 - val_mape: 15.6554 - val_mae: 0.2347 - val_mse: 0.1027 - val_NSE: 0.8989 - val_r_square: 0.919863 - mape: 6.7246 - mae: 0.0829 - mse: 0.0151 - NSE: 0.9877 - r_square: 0.99 - ETA: 4:54 - loss: 0.0363 - mape: 6.7252 - mae: 0.0829 - mse: 0.0151 - NSE: 0.9877 - r_square: 0.9 - ETA: 4:54 - loss: 0.0363 - mape: 6.7252 - mae: 0.0829 - mse: 0.0151 - NSE: 0.9877 - r_square: 0.99 - ETA: 4:54 - loss: 0.0364 - mape: 6.7321 - mae: 0.0830 - mse: 0.0151 - NSE: 0.9876 - r_square: 0.9 - ETA: 4:53 - loss: 0.0366 - mape: 6.7513 - mae: 0.0832 - mse: 0.0152 - NSE: 0.9876 - r_squ - ETA: 4:52 - loss: 0.0365 - mape: 6.7399 - mae: 0.0831 - mse: 0.0151 - NSE: 0.9876 - r_square: 0.990 - ETA: 4:51 - loss: 0.0365 - mape: 6.7384 - mae: 0.0831 - mse: 0.0151 - NSE: 0.9876 - r_square: - ETA: 4:51 - ETA: 1:47 - loss: 0.0357 - mape: 6.6062 - mae: 0.0812 - mse: 0.0147 - NSE: 0.9880 - r_square: 0.99 - ETA: 1:47 - loss: 0.0357 - mape: 6.6089 - mae: 0.0812 - mse: 0.0148 - NSE: 0.9879 - r_square: 0.990 - ETA: 1:46 - loss: 0.0357 - mape: 6.6098 - mae: 0.0813 - mse: 0.0148 - NSE: 0.9879 - r_square: 0. - ETA: 1:46 - loss: 0.0357 - mape: 6.6144 - mae: 0.0813 - mse: 0.0148 - NSE: 0.9879 - r_square: - ETA: 1:46 - loss: 0.0358 - mape: 6.6192 - mae: 0.0814 - mse: 0.0148 - NSE: 0.9879 - r_square: 0 - ETA: 1:45 - loss: 0.0359 - mape: 6.6276 - mae: 0.0815 - mse: 0.0148 - NSE: 0.9879 - r - ETA: 1:44 - loss: 0.0359 - mape: 6.6337 - mae: 0.0816 - mse: 0.0148 - NSE: 0.9879 - r_square: 0.99 - ETA: 1:44 - loss: 0.0359 - mape: 6.6339 - mae: 0.0816 - mse: 0.0148 - NSE: 0.9879 - r_square: - ETA: 1:43 - loss: 0.0359 - mape: 6.6355 - mae: 0.0816 - mse: 0.0148 - NSE: 0.9879 - r_square: 0.990 - ETA: 1:43 - loss: 0.0359 - mape: 6.6359 - mae: 0.0816 - mse: 0.0149 - NSE: 0.9879 - r_square: 0. - ETA: 1:43 - loss: 0.0359 - mape: 6.6372 - mae: 0.0816 - mse: 0.0149 - NSE: 0.9879 - r_square: 0.990 - ETA: 1:43 - loss: 0.0359 - mape: 6.6374 - mae: 0.0816 - mse: 0.0149 - NSE: 0.9879 - r_square - ETA: 1:42 - loss: 0.0359 - mape: 6.6386 - mae: 0.0816 - mse: 0.0149 - NSE: 0.9879 - r_square: 0. - ETA: 1:42 - loss: 0.03\n",
      "Epoch 7/15\n",
      "12002500/12002500 [==============================] - 448s 37us/sample - loss: 0.0348 - mape: 6.4889 - mae: 0.0791 - mse: 0.0143 - NSE: 0.9881 - r_square: 0.9904 - val_loss: 0.1558 - val_mape: 13.3772 - val_mae: 0.1960 - val_mse: 0.0738 - val_NSE: 0.9274 - val_r_square: 0.93710394 - mape: 6.9620 - mae: 0.0850 - mse: 0.0166 - NSE: 0.9863 - r_square: 0.98 - ETA: 6:37 - loss: 0.0395 - mape: 6.9775 - mae: 0.0852 - mse: 0.0167 - NSE: 0.9863 - r_square:  - ETA: 6:34 - loss: 0.0391 - mape: 6.9446 - mae: 0.0848 - mse: 0.0165 - NSE: 0.9864 - r_square: 0. - ETA: 6:32 - loss: 0.0388 - mape: 6.9172 - mae: 0.0845 - mse: 0.0163 - NSE: 0.9865 - r_square: 0.989 - ETA: 6:32 - loss: 0.0388 - mape: 6.9135 - mae: 0.0844 - mse: 0.0163 - NSE: 0.9866 - r_square: - ETA: 6:28 - loss: 0.0383 - mape: 6.8764 - mae: 0.0840 - mse: 0.0161 - NSE: 0.9867 - r_square: 0.989 - ETA: 6:28 - loss: 0.0383 - mape: 6.8699 - mae: 0.0839 - mse: 0.0161 - NSE: 0.9868 - r_square: 0.989 - ETA: 6:27 - loss: 0.0382 - mape: 6.8628 - mae: 0.0838 - mse: 0.0160 - NSE: 0.9868 - r_square: 0.98 - ETA: 6:26 - loss: 0.0380 - mape: 6.8477 - mae: 0.0837 - mse: 0.0160 - NSE: 0.9869 - r_square: 0. - ETA: 6:24 - loss: 0.0378 - mape: 6.8264 - mae: 0.0834 - mse: 0.0158 - NSE: 0.9870 - r_square:  - ETA: 6:21 - loss: 0.0374 - mape: 6.7893 - mae: 0.0830 - mse: 0.0156 - NSE: 0.9871 - r_square: 0.989 - ETA: 6:21 - loss: 0.0373 - mape: 6.7819 - mae: 0.0829 - mse: 0.0156 - NSE: 0.9872 - r_square: 0. - ETA: 6:19 - loss: 0.0371 - mape: 6.7609 - - ETA: 3:22 - loss: 0.0366 - mape: 6.6244 - mae: 0.0806 - mse: 0.0152 - NSE: 0.9876 - r_square: 0.990 - ETA: 3:21 - loss: 0.0366 - mape: 6.6239 - mae: 0.0806 - mse: 0.0152 - NSE: 0.9876 - r_square - ETA: 3:21 - loss: 0.0367 - mape: 6.6326 - mae: 0.0807 - mse: 0.0153 - NSE: 0.9876 - r_square: 0.99 - ETA: 3:20 - loss: 0.0367 - mape: 6.6312 - mae: 0.0807 - mse: 0.0152 - NSE: 0.9876 - r_square: 0.9 - ETA: 3:20 - loss: 0.0366 - mape: 6.6288 - mae: 0.0807 - mse: 0.0152 - NSE: 0.9876 - r_square:  - ETA: 3:19 - loss: 0.0367 - mape: 6.6341 - mae: 0.0807 - mse: 0.0153 - NSE: 0.9875 - r_square: 0.99 - ETA: 3:19 - loss: 0.0367 - mape: 6.6370 - mae: 0.0808 - mse: 0.0153 - NSE: 0.9875 - r_square - ETA: 3:18 - loss: 0.0368 - mape: 6.6426 - mae: 0.0808 - mse: 0.0153 - NSE: 0.9875 - r_square: 0.990 - ETA: 3:18 - loss: 0.0368 - mape: 6.6419 - mae: 0.0808 - mse: 0.0153 - NSE: 0.9875 - r_square: 0.99 - ETA: 3:18 - loss: 0.0368 - mape: 6.6405 - mae: 0.0808 - mse: 0.0153 - NSE: 0.987 - ETA: 22s - loss: 0.0351 - mape: 6.5187 - mae: 0.0795 - mse: 0.0145 - NSE: 0.9881 - r_ - ETA: 22s - loss: 0.0352 - mape: 6.5200 - mae: 0.0795 - mse: 0.0145 - NSE: - ETA: 21s - loss: 0.0351 - mape: 6.5158 - mae: 0.0795 - mse: 0.0145 - NSE: 0.9881 - r_squa - ETA: 20s - loss: 0.0351 - mape: 6.5143 - mae: 0.0794 - mse: 0.0145 - NSE: 0.9881 - r_square: 0.99 - ETA: 20s - loss: 0.0351 - mape: 6.5139 - mae: 0.0794 - mse: 0.0145 - NSE: 0.9881 -  - ETA: 19s - loss: 0.0351 - mape: 6.5165 - mae: 0.0795 - mse: 0.0145 - NSE: 0.9881 - r_squa - ETA: 19s - loss: 0.0351 - mape: 6.5148 - mae: 0.0794 - mse: 0.0145 - NSE: 0.9881 - r_sq - ETA: 18s - loss: 0.0351 - mape: 6.5149 - mae: 0.0794 - mse: 0.0145 - NSE: 0.9881 - r_square: 0. - ETA: 18s - loss: 0.0351 - mape: 6.5142 - mae: 0.0794 - mse: 0.0145 - NSE: 0.9881 - r_squa - ETA: 18s - loss: 0.0351 - mape: 6.5126 - mae: 0.0794 - mse: 0.0144 - NSE: 0.9881 - r_square:  - ETA: 18s - loss: 0.0351 - mape: 6.5115 - mae: 0.0794 - mse: 0.0144 - NSE: 0.9881 - r_square:  - ETA: 17s - loss: 0.0351 - mape: 6.5107 - mae: 0.0794 - mse: 0.0144 - NSE: 0.9881 - r_square:  - ETA: 17s - loss: 0.0350 - mape: 6.5100 - mae: 0.0794 - mse: 0.0144 - NSE: 0.9881 - r_square - ETA: 17s - loss: 0.0350 - mape: 6.5086 - mae: 0.0794 - mse: 0.0144 - NSE: 0.9881 - r_sq - ETA: 16s - loss: 0.0350 - mape: 6.5075 - mae: 0.0794 - mse: 0.0144 - NSE: 0.9881 - r_square:  - ETA: 16s - loss: 0.0350 - mape: 6.5068 - mae: 0.0793 - mse: 0.0144 - NSE: 0.9881 - r_square: 0.99 - ETA: 16s - loss: 0.0350 - mape: 6.5065 - mae: 0.0793 - mse: 0.0144 - NSE: 0.9881 - r_square: 0.99 - ETA: 16s - loss: 0.0350 - mape: 6.5061 - mae: 0.0793 - mse: 0.0144 - NSE: 0.9881 - r_square: 0.99 - ETA: 16s - loss: 0.0350 - mape: 6.5057 - mae: 0.0793 - mse: 0.0144 - NSE: 0.9881 - r_square: 0. - ETA: 16s - loss: 0.0350 - mape: 6.5052 - mae: 0.0793 - mse: 0.0144 - NSE: 0.9881 - r_square - ETA: 15s - loss: 0.0350 - mape: 6.5039 - mae: 0.0793 - mse: 0.0144 - NSE: 0.9881 - r_squa - ETA: 15s - loss: 0.0350 - mape: 6.5028 - mae: 0.0793 - mse: 0.0144 - NSE: 0.9881 - r_ - ETA: 14s - loss: 0.0350 - mape: 6.5013 - mae: 0.0793 - mse: 0.0144 - NSE: 0.9881 - r_square - ETA: 14s - loss: 0.0350 - mape: 6.5041 - mae: 0.0793 - mse: 0.0144 - NSE: 0.9881 - r_square: 0. - ETA: 14s - loss: 0.0350 - mape: 6.5038 - mae: 0.0793 - mse: 0.0144 - NSE: 0.9881 - r_square: 0.99 - ETA: 14s - loss: 0.0350 - mape: 6.5035 - mae: 0.0793 - mse: 0.0144 - NSE: 0.9881 - r_square: 0.99 - ETA: 1\n",
      "Epoch 8/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12002500/12002500 [==============================] - 452s 38us/sample - loss: 0.0254 - mape: 5.5249 - mae: 0.0662 - mse: 0.0096 - NSE: 0.9920 - r_square: 0.9933 - val_loss: 0.1856 - val_mape: 14.3409 - val_mae: 0.2128 - val_mse: 0.0887 - val_NSE: 0.9126 - val_r_square: 0.92626 - mape: 5.7014 - mae: 0.0690 - mse: 0.0102 - NSE:  - ETA: 5:12 - loss: 0.0265 - mape: 5.6929 - mae: 0.0689 - mse: 0.0102 - NSE: 0.9917 - r_square: 0. - ETA: 5:11 - loss: 0.0265 - mape: 5.6901 - mae: 0.0688 - mse: 0.0102 - NSE: 0.9917 - r_square: 0.993 - ETA: 5:11 - loss: 0.0265 - mape: 5.6903 - mae: 0.0688 - mse: 0.0101 - NSE: 0.9917 - r_square: 0.99 - ETA: 5:10 - loss: 0.0265 - mape: 5.6893 - mae: 0.0688 - mse: 0.0101 - NSE: 0.9917 - r_square: 0.9 - ETA: 5:10 - loss: 0.0265 - mape: 5.6879 - mae: 0.0688 - mse: 0.0101 - NSE: 0.9917 - r_square: - ETA: 5:09 - loss: 0.0265 - mape: 5.6833 - mae: 0.0687 - mse: 0.0101 - NSE: 0.9917 - r_square: 0.993 - ETA: 5:09 - loss: 0.0264 - mape: 5.6827 - mae: 0. - ETA: 2:10 - loss: 0.0254 - mape: 5.5234 - mae: 0.0663 - mse:\n",
      "Epoch 9/15\n",
      "12002500/12002500 [==============================] - 453s 38us/sample - loss: 0.0236 - mape: 5.2579 - mae: 0.0630 - mse: 0.0087 - NSE: 0.9928 - r_square: 0.9941 - val_loss: 0.1348 - val_mape: 13.1225 - val_mae: 0.1877 - val_mse: 0.0632 - val_NSE: 0.9377 - val_r_square: 0.9434242 - mape: 5.3535 - mae: 0.0640 - mse: 0.0090 - NSE: 0.9926 - r_squa - ETA: 3:57 - loss: 0.0242 - mape: 5.3502 - mae: 0.0640 - mse: 0.0090 - NSE: 0.9926 - r_square: 0 - ETA: 3:56 - loss: 0.0242 - mape: 5.3493 - mae: 0.0640 - mse: 0.0090 - NSE: 0.9926 - r_square: 0.993 - ETA: 3:56 - loss: 0.0242 - mape: 5.3492 - mae: 0.0640 - mse: 0.0090 - NSE: 0.9926 - r_square: 0.9 - ETA: 3:56 - loss: 0.0242 - mape: 5.3497 - mae: 0.0640 - mse: 0.0090 - NSE: 0.9926 - r_square: 0.993 - ETA: 3:56 - loss: 0.0242 - mape: 5.3 - ETA: 58s - loss: 0.0237 - mape: 5.2736 - mae: 0.0631 - mse: 0.0088 - NSE: 0.9928 - r_squa - ETA: 58s - loss: 0.0237 - mape: 5.2722 - mae: 0.0631 - mse: 0.0088 - NSE: 0.9928 -\n",
      "Epoch 10/15\n",
      "12002500/12002500 [==============================] - 450s 37us/sample - loss: 0.0227 - mape: 5.0750 - mae: 0.0610 - mse: 0.0082 - NSE: 0.9932 - r_square: 0.9945 - val_loss: 0.1809 - val_mape: 14.3788 - val_mae: 0.2106 - val_mse: 0.0863 - val_NSE: 0.9150 - val_r_square: 0.9234\n",
      "Epoch 11/15\n",
      "12002500/12002500 [==============================] - 454s 38us/sample - loss: 0.0222 - mape: 4.9964 - mae: 0.0601 - mse: 0.0080 - NSE: 0.9935 - r_square: 0.9947 - val_loss: 0.1517 - val_mape: 13.9542 - val_mae: 0.2025 - val_mse: 0.0717 - val_NSE: 0.9295 - val_r_square: 0.9358\n",
      "15 5 5 0\n",
      "Train on 12002500 samples, validate on 2885500 samples\n",
      "Epoch 1/15\n",
      "12002500/12002500 [==============================] - 331s 28us/sample - loss: 2.9927 - mape: 83.0028 - mae: 0.8925 - mse: 1.4927 - NSE: -0.2153 - r_square: 1.4144e-05 - val_loss: 2.0260 - val_mape: 76.1469 - val_mae: 0.8294 - val_mse: 1.0088 - val_NSE: 0.0134 - val_r_square: 2.5002e-14\n",
      "Epoch 2/15\n",
      "12002500/12002500 [==============================] - 323s 27us/sample - loss: 2.4569 - mape: 82.9466 - mae: 0.8799 - mse: 1.2254 - NSE: 0.0075 - r_square: 1.9712e-14 - val_loss: 2.0262 - val_mape: 75.8897 - val_mae: 0.8286 - val_mse: 1.0089 - val_NSE: 0.0133 - val_r_square: 2.5469e-14\n",
      "Epoch 3/15\n",
      "12002500/12002500 [==============================] - 339s 28us/sample - loss: 2.4569 - mape: 82.9456 - mae: 0.8799 - mse: 1.2254 - NSE: 0.0075 - r_square: 1.9894e-14 - val_loss: 2.0254 - val_mape: 76.3483 - val_mae: 0.8299 - val_mse: 1.0085 - val_NSE: 0.0137 - val_r_square: 9.7190e-157 - mape: 82.9439 - mae: 0.8798 - mse: 1.2253 - NSE: 0.0075 - r_square - ETA: 13s - loss: 2.4568 - mape: 82.9436 - mae: 0.8799 - mse: 1.2254 - NSE: 0.0075 - r_square: 1.9888e-1 - ETA: 13s - loss: 2.4568 - mape: 82.9436 - mae: 0.8799 - mse: 1.2254 - NSE: 0.0075 - r_squa - ETA: 12s - loss: 2.4568 - mape: 82.9445 - mae: 0.8799 - mse: 1.2253 - NSE: 0.0075 - r_square: 1.9882e - ETA: 12s - loss: 2.4568 - mape\n",
      "Epoch 4/15\n",
      "12002500/12002500 [==============================] - 339s 28us/sample - loss: 2.4569 - mape: 82.9462 - mae: 0.8799 - mse: 1.2254 - NSE: 0.0075 - r_square: 1.9683e-14 - val_loss: 2.0250 - val_mape: 76.8688 - val_mae: 0.8315 - val_mse: 1.0083 - val_NSE: 0.0138 - val_r_square: 2.1813e-14\n",
      "Epoch 5/15\n",
      " 7412096/12002500 [=================>............] - ETA: 1:49 - loss: 2.4555 - mape: 82.9462 - mae: 0.8796 - mse: 1.2247 - NSE: 0.0074 - r_square: 1.9698e-14"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-9bc332ad379e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m                     \u001b[1;31m#fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                     \u001b[0mearly_stopping_monitor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping_monitor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                     \u001b[1;31m# Saving results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\thesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\.conda\\envs\\thesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    678\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\.conda\\envs\\thesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mins\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m               \u001b[1;31m# Do not slice the training phase flag.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m               \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m               \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\thesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[1;34m(arrays, start, stop)\u001b[0m\n\u001b[0;32m    646\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m     return [\n\u001b[0;32m    650\u001b[0m         \u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\thesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    646\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m     return [\n\u001b[0;32m    650\u001b[0m         \u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for reg in reg_consts:\n",
    "    for n1 in layer_1_neurons:\n",
    "        for n2 in layer_2_neurons:\n",
    "            for n3 in layer_3_neurons:\n",
    "                for weight in weightage:\n",
    "                    print(n1,n2,n3,reg)\n",
    "                    K.clear_session()\n",
    "                    model = Sequential()\n",
    "                    #model.add(Dense(n1, activation = 'relu', input_shape = (1,)))\n",
    "                    model.add(Dense(n1, activation = 'relu', kernel_regularizer=l2(reg),input_shape = (5,)))\n",
    "                    model.add(Dense(n2, activation = 'relu', kernel_regularizer=l2(reg)))\n",
    "                    model.add(Dense(n3, activation = 'relu', kernel_regularizer=l2(reg)))\n",
    "\n",
    "                    model.add(Dense(2))\n",
    "                    grads_u = K.gradients(model.output[:,0], model.input)[0]\n",
    "                    grads_h = K.gradients(model.output[:,1], model.input)[0]\n",
    "\n",
    "\n",
    "                    du_dx, du_dt, dh_dx = grads_u[:,0],grads_u[:,1],grads_h[:,0]\n",
    "                    calc_grads_inputs = K.stack((du_dx, du_dt, dh_dx, model.input[:,3],model.input[:,4]), axis=1)\n",
    "                    # model.summary()\n",
    "                    #Compile the model\n",
    "                    model.compile(optimizer = 'adam', loss = [custom_loss(calc_grads_inputs, weight)], metrics=['mape', 'mae', 'mse',NSE, r_square])\n",
    "                    #fit the model\n",
    "                    early_stopping_monitor = EarlyStopping(patience = 2, verbose=False)\n",
    "                    history = model.fit(X_train,Y_train, epochs=epochs, batch_size=128, validation_data=(X_val,Y_val), callbacks=[early_stopping_monitor])\n",
    "\n",
    "                    # Saving results\n",
    "                    val_loss = history.history['val_loss'][-1]\n",
    "                    val_mae = history.history['val_mae'][-1]\n",
    "                    val_mse = history.history['val_mse'][-1]\n",
    "                    val_mape = history.history['val_mape'][-1]\n",
    "                    val_nse = history.history['val_NSE'][-1]\n",
    "                    val_r_square = history.history['val_r_square'][-1]\n",
    "\n",
    "                    results = results.append({'n1':n1,'n2':n2,'n3':n3, 'epochs':len(history.history['val_loss']),\n",
    "                                  'reg':reg,'val_r2':val_r_square, 'val_nse':val_nse, 'val_mse':val_mse, 'val_loss':val_loss,\n",
    "                                            'val_mae':val_mae, 'val_mape':val_mape, 'weight':weight }, ignore_index=True)\n",
    "                    \n",
    "                    # For weighted PINN, val_mse can also be used to select the best model\n",
    "                    if val_loss < best_val_loss: \n",
    "                        best_val_loss = val_loss\n",
    "                        best_model = model\n",
    "                        best_n1 = n1\n",
    "                        best_n2 = n2\n",
    "                        best_n3 = n3\n",
    "                        best_reg = reg\n",
    "                        best_history = history\n",
    "                        model.save(save_model_path)\n",
    "                        results.to_csv(save_results_path)\n",
    "\n",
    "results.to_csv(save_results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-03T19:12:39.213568Z",
     "iopub.status.busy": "2020-09-03T19:12:39.212520Z",
     "iopub.status.idle": "2020-09-03T19:12:39.216280Z",
     "shell.execute_reply": "2020-09-03T19:12:39.217164Z"
    },
    "papermill": {
     "duration": 0.812572,
     "end_time": "2020-09-03T19:12:39.217375",
     "exception": false,
     "start_time": "2020-09-03T19:12:38.404803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 15)                90        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 80        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 12        \n",
      "=================================================================\n",
      "Total params: 212\n",
      "Trainable params: 212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 1095.738968,
   "end_time": "2020-09-03T19:12:53.052539",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-03T18:54:37.313571",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
